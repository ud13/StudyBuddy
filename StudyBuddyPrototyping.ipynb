{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "47eTBHYNP4g1"
      },
      "source": [
        "# StudyBuddy Prototyping\n",
        "copied from Introduction to LangChain v0.1.0 and LCEL: LangChain Powered RAG\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aVHd6POM0JFN"
      },
      "source": [
        "#### TaInstalling Required Libraries\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Help on QdrantClient in module qdrant_client.qdrant_client object:\n",
            "\n",
            "class QdrantClient(qdrant_client.qdrant_fastembed.QdrantFastembedMixin)\n",
            " |  QdrantClient(location: Optional[str] = None, url: Optional[str] = None, port: Optional[int] = 6333, grpc_port: int = 6334, prefer_grpc: bool = False, https: Optional[bool] = None, api_key: Optional[str] = None, prefix: Optional[str] = None, timeout: Optional[int] = None, host: Optional[str] = None, path: Optional[str] = None, force_disable_check_same_thread: bool = False, grpc_options: Optional[Dict[str, Any]] = None, auth_token_provider: Union[Callable[[], str], Callable[[], Awaitable[str]], NoneType] = None, **kwargs: Any)\n",
            " |  \n",
            " |  Entry point to communicate with Qdrant service via REST or gRPC API.\n",
            " |  \n",
            " |  It combines interface classes and endpoint implementation.\n",
            " |  Additionally, it provides custom implementations for frequently used methods like initial collection upload.\n",
            " |  \n",
            " |  All methods in QdrantClient accept both gRPC and REST structures as an input.\n",
            " |  Conversion will be performed automatically.\n",
            " |  \n",
            " |  .. note::\n",
            " |      This module methods are wrappers around generated client code for gRPC and REST methods.\n",
            " |      If you need lower-level access to generated clients, use following properties:\n",
            " |  \n",
            " |      - :py:attr:`QdrantClient.grpc_points`\n",
            " |      - :py:attr:`QdrantClient.grpc_collections`\n",
            " |      - :py:attr:`QdrantClient.rest`\n",
            " |  \n",
            " |  .. note::\n",
            " |      If you need async, please consider using Async Implementations of QdrantClient.\n",
            " |  \n",
            " |      - :class:`qdrant_client.async_qdrant_client`\n",
            " |  \n",
            " |  Args:\n",
            " |      location:\n",
            " |          If `\":memory:\"` - use in-memory Qdrant instance.\n",
            " |          If `str` - use it as a `url` parameter.\n",
            " |          If `None` - use default values for `host` and `port`.\n",
            " |      url: either host or str of \"Optional[scheme], host, Optional[port], Optional[prefix]\".\n",
            " |          Default: `None`\n",
            " |      port: Port of the REST API interface. Default: 6333\n",
            " |      grpc_port: Port of the gRPC interface. Default: 6334\n",
            " |      prefer_grpc: If `true` - use gPRC interface whenever possible in custom methods.\n",
            " |      https: If `true` - use HTTPS(SSL) protocol. Default: `None`\n",
            " |      api_key: API key for authentication in Qdrant Cloud. Default: `None`\n",
            " |      prefix:\n",
            " |          If not `None` - add `prefix` to the REST URL path.\n",
            " |          Example: `service/v1` will result in `http://localhost:6333/service/v1/{qdrant-endpoint}` for REST API.\n",
            " |          Default: `None`\n",
            " |      timeout:\n",
            " |          Timeout for REST and gRPC API requests.\n",
            " |          Default: 5 seconds for REST and unlimited for gRPC\n",
            " |      host: Host name of Qdrant service. If url and host are None, set to 'localhost'.\n",
            " |          Default: `None`\n",
            " |      path: Persistence path for QdrantLocal. Default: `None`\n",
            " |      force_disable_check_same_thread:\n",
            " |          For QdrantLocal, force disable check_same_thread. Default: `False`\n",
            " |          Only use this if you can guarantee that you can resolve the thread safety outside QdrantClient.\n",
            " |      auth_token_provider: Callback function to get Bearer access token. If given, the function will be called before each request to get the token.\n",
            " |      **kwargs: Additional arguments passed directly into REST client initialization\n",
            " |  \n",
            " |  Method resolution order:\n",
            " |      QdrantClient\n",
            " |      qdrant_client.qdrant_fastembed.QdrantFastembedMixin\n",
            " |      qdrant_client.client_base.QdrantBase\n",
            " |      builtins.object\n",
            " |  \n",
            " |  Methods defined here:\n",
            " |  \n",
            " |  __del__(self) -> None\n",
            " |  \n",
            " |  __init__(self, location: Optional[str] = None, url: Optional[str] = None, port: Optional[int] = 6333, grpc_port: int = 6334, prefer_grpc: bool = False, https: Optional[bool] = None, api_key: Optional[str] = None, prefix: Optional[str] = None, timeout: Optional[int] = None, host: Optional[str] = None, path: Optional[str] = None, force_disable_check_same_thread: bool = False, grpc_options: Optional[Dict[str, Any]] = None, auth_token_provider: Union[Callable[[], str], Callable[[], Awaitable[str]], NoneType] = None, **kwargs: Any)\n",
            " |      Initialize self.  See help(type(self)) for accurate signature.\n",
            " |  \n",
            " |  batch_update_points(self, collection_name: str, update_operations: Sequence[Union[qdrant_client.http.models.models.UpsertOperation, qdrant_client.http.models.models.DeleteOperation, qdrant_client.http.models.models.SetPayloadOperation, qdrant_client.http.models.models.OverwritePayloadOperation, qdrant_client.http.models.models.DeletePayloadOperation, qdrant_client.http.models.models.ClearPayloadOperation, qdrant_client.http.models.models.UpdateVectorsOperation, qdrant_client.http.models.models.DeleteVectorsOperation]], wait: bool = True, ordering: Optional[qdrant_client.http.models.models.WriteOrdering] = None, **kwargs: Any) -> List[qdrant_client.http.models.models.UpdateResult]\n",
            " |      Batch update points in the collection.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          update_operations: List of update operations\n",
            " |          wait: Await for the results to be processed.\n",
            " |              - If `true`, result will be returned only when all changes are applied\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |          ordering (Optional[WriteOrdering]): Define strategy for ordering of the points. Possible values:\n",
            " |      \n",
            " |              - `weak` (default) - write operations may be reordered, works faster\n",
            " |              - `medium` - write operations go through dynamically selected leader, may be inconsistent for a short period of time in case of leader change\n",
            " |              - `strong` - Write operations go through the permanent leader, consistent, but may be unavailable if leader is down\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation results\n",
            " |  \n",
            " |  clear_payload(self, collection_name: str, points_selector: Union[List[Union[int, str, points_pb2.PointId]], qdrant_client.http.models.models.Filter, points_pb2.Filter, qdrant_client.http.models.models.PointIdsList, qdrant_client.http.models.models.FilterSelector, points_pb2.PointsSelector], wait: bool = True, ordering: Optional[qdrant_client.http.models.models.WriteOrdering] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, **kwargs: Any) -> qdrant_client.http.models.models.UpdateResult\n",
            " |      Delete all payload for selected points\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          wait: Await for the results to be processed.\n",
            " |              - If `true`, result will be returned only when all changes are applied\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |          points_selector: List of affected points, filter or points selector. Example\n",
            " |              - `points=[1, 2, 3, \"cd3b53f0-11a7-449f-bc50-d06310e7ed90\"]`\n",
            " |              - `points=Filter(must=[FieldCondition(key='rand_number', range=Range(gte=0.7))])`\n",
            " |          ordering (Optional[WriteOrdering]): Define strategy for ordering of the points. Possible values:\n",
            " |      \n",
            " |              - `weak` (default) - write operations may be reordered, works faster\n",
            " |              - `medium` - write operations go through dynamically selected leader, may be inconsistent for a short period of time in case of leader change\n",
            " |              - `strong` - Write operations go through the permanent leader, consistent, but may be unavailable if leader is down\n",
            " |      \n",
            " |          shard_key_selector:\n",
            " |              Defines the shard groups that should be used to write updates into.\n",
            " |              If multiple shard_keys are provided, the update will be written to each of them.\n",
            " |              Only works for collections with `custom` sharding method.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation result\n",
            " |  \n",
            " |  close(self, grpc_grace: Optional[float] = None, **kwargs: Any) -> None\n",
            " |      Closes the connection to Qdrant\n",
            " |      \n",
            " |      Args:\n",
            " |          grpc_grace: Grace period for gRPC connection close. Default: None\n",
            " |  \n",
            " |  collection_exists(self, collection_name: str, **kwargs: Any) -> bool\n",
            " |      Check whether collection already exists\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |      \n",
            " |      Returns:\n",
            " |          True if collection exists, False if not\n",
            " |  \n",
            " |  count(self, collection_name: str, count_filter: Union[qdrant_client.http.models.models.Filter, points_pb2.Filter, NoneType] = None, exact: bool = True, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, **kwargs: Any) -> qdrant_client.http.models.models.CountResult\n",
            " |      Count points in the collection.\n",
            " |      \n",
            " |      Count points in the collection matching the given filter.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: name of the collection to count points in\n",
            " |          count_filter: filtering conditions\n",
            " |          exact:\n",
            " |              If `True` - provide the exact count of points matching the filter.\n",
            " |              If `False` - provide the approximate count of points matching the filter. Works faster.\n",
            " |      \n",
            " |          shard_key_selector:\n",
            " |              This parameter allows to specify which shards should be queried.\n",
            " |              If `None` - query all shards. Only works for collections with `custom` sharding method.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Amount of points in the collection matching the filter.\n",
            " |  \n",
            " |  create_collection(self, collection_name: str, vectors_config: Union[qdrant_client.http.models.models.VectorParams, Mapping[str, qdrant_client.http.models.models.VectorParams]], sparse_vectors_config: Optional[Mapping[str, qdrant_client.http.models.models.SparseVectorParams]] = None, shard_number: Optional[int] = None, sharding_method: Optional[qdrant_client.http.models.models.ShardingMethod] = None, replication_factor: Optional[int] = None, write_consistency_factor: Optional[int] = None, on_disk_payload: Optional[bool] = None, hnsw_config: Union[qdrant_client.http.models.models.HnswConfigDiff, collections_pb2.HnswConfigDiff, NoneType] = None, optimizers_config: Union[qdrant_client.http.models.models.OptimizersConfigDiff, collections_pb2.OptimizersConfigDiff, NoneType] = None, wal_config: Union[qdrant_client.http.models.models.WalConfigDiff, collections_pb2.WalConfigDiff, NoneType] = None, quantization_config: Union[qdrant_client.http.models.models.ScalarQuantization, qdrant_client.http.models.models.ProductQuantization, qdrant_client.http.models.models.BinaryQuantization, collections_pb2.QuantizationConfig, NoneType] = None, init_from: Union[qdrant_client.http.models.models.InitFrom, str, NoneType] = None, timeout: Optional[int] = None, **kwargs: Any) -> bool\n",
            " |      Create empty collection with given parameters\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection to recreate\n",
            " |          vectors_config:\n",
            " |              Configuration of the vector storage. Vector params contains size and distance for the vector storage.\n",
            " |              If dict is passed, service will create a vector storage for each key in the dict.\n",
            " |              If single VectorParams is passed, service will create a single anonymous vector storage.\n",
            " |          sparse_vectors_config:\n",
            " |              Configuration of the sparse vector storage.\n",
            " |              The service will create a sparse vector storage for each key in the dict.\n",
            " |          shard_number: Number of shards in collection. Default is 1, minimum is 1.\n",
            " |          sharding_method:\n",
            " |              Defines strategy for shard creation.\n",
            " |              Option `auto` (default) creates defined number of shards automatically.\n",
            " |              Data will be distributed between shards automatically.\n",
            " |              After creation, shards could be additionally replicated, but new shards could not be created.\n",
            " |              Option `custom` allows to create shards manually, each shard should be created with assigned\n",
            " |              unique `shard_key`. Data will be distributed between based on `shard_key` value.\n",
            " |          replication_factor:\n",
            " |              Replication factor for collection. Default is 1, minimum is 1.\n",
            " |              Defines how many copies of each shard will be created.\n",
            " |              Have effect only in distributed mode.\n",
            " |          write_consistency_factor:\n",
            " |              Write consistency factor for collection. Default is 1, minimum is 1.\n",
            " |              Defines how many replicas should apply the operation for us to consider it successful.\n",
            " |              Increasing this number will make the collection more resilient to inconsistencies, but will\n",
            " |              also make it fail if not enough replicas are available.\n",
            " |              Does not have any performance impact.\n",
            " |              Have effect only in distributed mode.\n",
            " |          on_disk_payload:\n",
            " |              If true - point`s payload will not be stored in memory.\n",
            " |              It will be read from the disk every time it is requested.\n",
            " |              This setting saves RAM by (slightly) increasing the response time.\n",
            " |              Note: those payload values that are involved in filtering and are indexed - remain in RAM.\n",
            " |          hnsw_config: Params for HNSW index\n",
            " |          optimizers_config: Params for optimizer\n",
            " |          wal_config: Params for Write-Ahead-Log\n",
            " |          quantization_config: Params for quantization, if None - quantization will be disabled\n",
            " |          init_from: Use data stored in another collection to initialize this collection\n",
            " |          timeout:\n",
            " |              Wait for operation commit timeout in seconds.\n",
            " |              If timeout is reached - request will return with service error.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation result\n",
            " |  \n",
            " |  create_full_snapshot(self, wait: bool = True, **kwargs: Any) -> Optional[qdrant_client.http.models.models.SnapshotDescription]\n",
            " |      Create snapshot for a whole storage.\n",
            " |      \n",
            " |      Args:\n",
            " |          wait: Await for the snapshot to be created.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when the snapshot is created\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Snapshot description\n",
            " |  \n",
            " |  create_payload_index(self, collection_name: str, field_name: str, field_schema: Union[qdrant_client.http.models.models.PayloadSchemaType, qdrant_client.http.models.models.TextIndexParams, qdrant_client.http.models.models.IntegerIndexParams, int, collections_pb2.PayloadIndexParams, NoneType] = None, field_type: Union[qdrant_client.http.models.models.PayloadSchemaType, qdrant_client.http.models.models.TextIndexParams, qdrant_client.http.models.models.IntegerIndexParams, int, collections_pb2.PayloadIndexParams, NoneType] = None, wait: bool = True, ordering: Optional[qdrant_client.http.models.models.WriteOrdering] = None, **kwargs: Any) -> qdrant_client.http.models.models.UpdateResult\n",
            " |      Creates index for a given payload field.\n",
            " |      Indexed fields allow to perform filtered search operations faster.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          field_name: Name of the payload field\n",
            " |          field_schema: Type of data to index\n",
            " |          field_type: Same as field_schema, but deprecated\n",
            " |          wait: Await for the results to be processed.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when all changes are applied\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |          ordering (Optional[WriteOrdering]): Define strategy for ordering of the points. Possible values:\n",
            " |      \n",
            " |              - `weak` (default) - write operations may be reordered, works faster\n",
            " |              - `medium` - write operations go through dynamically selected leader, may be inconsistent for a short period of time in case of leader change\n",
            " |              - `strong` - Write operations go through the permanent leader, consistent, but may be unavailable if leader is down\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation Result\n",
            " |  \n",
            " |  create_shard_key(self, collection_name: str, shard_key: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]], shards_number: Optional[int] = None, replication_factor: Optional[int] = None, placement: Optional[List[int]] = None, **kwargs: Any) -> bool\n",
            " |      Create shard key for collection.\n",
            " |      \n",
            " |      Only works for collections with `custom` sharding method.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          shard_key: Shard key to create\n",
            " |          shards_number: How many shards to create for this key\n",
            " |          replication_factor: Replication factor for this key\n",
            " |          placement: List of peers to place shards on. If None - place on all peers.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation result\n",
            " |  \n",
            " |  create_shard_snapshot(self, collection_name: str, shard_id: int, wait: bool = True, **kwargs: Any) -> Optional[qdrant_client.http.models.models.SnapshotDescription]\n",
            " |      Create snapshot for a given shard.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          shard_id: Index of the shard\n",
            " |          wait: Await for the snapshot to be created.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when the snapshot is created.\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Snapshot description\n",
            " |  \n",
            " |  create_snapshot(self, collection_name: str, wait: bool = True, **kwargs: Any) -> Optional[qdrant_client.http.models.models.SnapshotDescription]\n",
            " |      Create snapshot for a given collection.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          wait: Await for the snapshot to be created.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when a snapshot is created\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Snapshot description\n",
            " |  \n",
            " |  delete(self, collection_name: str, points_selector: Union[List[Union[int, str, points_pb2.PointId]], qdrant_client.http.models.models.Filter, points_pb2.Filter, qdrant_client.http.models.models.PointIdsList, qdrant_client.http.models.models.FilterSelector, points_pb2.PointsSelector], wait: bool = True, ordering: Optional[qdrant_client.http.models.models.WriteOrdering] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, **kwargs: Any) -> qdrant_client.http.models.models.UpdateResult\n",
            " |      Deletes selected points from collection\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          wait: Await for the results to be processed.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when all changes are applied\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |          points_selector: Selects points based on list of IDs or filter.\n",
            " |              Examples\n",
            " |      \n",
            " |              - `points=[1, 2, 3, \"cd3b53f0-11a7-449f-bc50-d06310e7ed90\"]`\n",
            " |              - `points=Filter(must=[FieldCondition(key='rand_number', range=Range(gte=0.7))])`\n",
            " |          ordering (Optional[WriteOrdering]): Define strategy for ordering of the points. Possible values:\n",
            " |      \n",
            " |              - `weak` (default) - write operations may be reordered, works faster\n",
            " |              - `medium` - write operations go through dynamically selected leader, may be inconsistent for a short period of time in case of leader change\n",
            " |              - `strong` - Write operations go through the permanent leader, consistent, but may be unavailable if leader is down\n",
            " |      \n",
            " |          shard_key_selector:\n",
            " |              Defines the shard groups that should be used to write updates into.\n",
            " |              If multiple shard_keys are provided, the update will be written to each of them.\n",
            " |              Only works for collections with `custom` sharding method.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation result\n",
            " |  \n",
            " |  delete_collection(self, collection_name: str, timeout: Optional[int] = None, **kwargs: Any) -> bool\n",
            " |      Removes collection and all it's data\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection to delete\n",
            " |          timeout:\n",
            " |              Wait for operation commit timeout in seconds.\n",
            " |              If timeout is reached - request will return with service error.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation result\n",
            " |  \n",
            " |  delete_full_snapshot(self, snapshot_name: str, wait: bool = True, **kwargs: Any) -> Optional[bool]\n",
            " |      Delete snapshot for a whole storage.\n",
            " |      \n",
            " |      Args:\n",
            " |          snapshot_name: Snapshot name\n",
            " |          wait: Await for the snapshot to be deleted.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when the snapshot is deleted\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |      \n",
            " |      Returns:\n",
            " |          True if snapshot was deleted\n",
            " |  \n",
            " |  delete_payload(self, collection_name: str, keys: Sequence[str], points: Union[List[Union[int, str, points_pb2.PointId]], qdrant_client.http.models.models.Filter, points_pb2.Filter, qdrant_client.http.models.models.PointIdsList, qdrant_client.http.models.models.FilterSelector, points_pb2.PointsSelector], wait: bool = True, ordering: Optional[qdrant_client.http.models.models.WriteOrdering] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, **kwargs: Any) -> qdrant_client.http.models.models.UpdateResult\n",
            " |      Remove values from point's payload\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          wait: Await for the results to be processed.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when all changes are applied\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |          keys: List of payload keys to remove\n",
            " |          points: List of affected points, filter or points selector.\n",
            " |              Example\n",
            " |                  - `points=[1, 2, 3, \"cd3b53f0-11a7-449f-bc50-d06310e7ed90\"]`\n",
            " |                  - `points=Filter(must=[FieldCondition(key='rand_number', range=Range(gte=0.7))])`\n",
            " |          ordering (Optional[WriteOrdering]): Define strategy for ordering of the points. Possible values:\n",
            " |      \n",
            " |              - `weak` (default) - write operations may be reordered, works faster\n",
            " |              - `medium` - write operations go through dynamically selected leader, may be inconsistent for a short period of time in case of leader change\n",
            " |              - `strong` - Write operations go through the permanent leader, consistent, but may be unavailable if leader is downn\n",
            " |      \n",
            " |          shard_key_selector:\n",
            " |              Defines the shard groups that should be used to write updates into.\n",
            " |              If multiple shard_keys are provided, the update will be written to each of them.\n",
            " |              Only works for collections with `custom` sharding method.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation result\n",
            " |  \n",
            " |  delete_payload_index(self, collection_name: str, field_name: str, wait: bool = True, ordering: Optional[qdrant_client.http.models.models.WriteOrdering] = None, **kwargs: Any) -> qdrant_client.http.models.models.UpdateResult\n",
            " |      Removes index for a given payload field.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          field_name: Name of the payload field\n",
            " |          wait: Await for the results to be processed.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when all changes are applied\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |          ordering (Optional[WriteOrdering]): Define strategy for ordering of the points. Possible values:\n",
            " |      \n",
            " |              - `weak` (default) - write operations may be reordered, works faster\n",
            " |              - `medium` - write operations go through dynamically selected leader, may be inconsistent for a short period of time in case of leader change\n",
            " |              - `strong` - Write operations go through the permanent leader, consistent, but may be unavailable if leader is down\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation Result\n",
            " |  \n",
            " |  delete_shard_key(self, collection_name: str, shard_key: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]], **kwargs: Any) -> bool\n",
            " |      Delete shard key for collection.\n",
            " |      \n",
            " |      Only works for collections with `custom` sharding method.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          shard_key: Shard key to delete\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation result\n",
            " |  \n",
            " |  delete_shard_snapshot(self, collection_name: str, shard_id: int, snapshot_name: str, wait: bool = True, **kwargs: Any) -> Optional[bool]\n",
            " |      Delete snapshot for a given shard.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          shard_id: Index of the shard\n",
            " |          snapshot_name: Snapshot id\n",
            " |          wait: Await for the snapshot to be deleted.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when the snapshot is deleted\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |      \n",
            " |      Returns:\n",
            " |          True if snapshot was deleted\n",
            " |  \n",
            " |  delete_snapshot(self, collection_name: str, snapshot_name: str, wait: bool = True, **kwargs: Any) -> Optional[bool]\n",
            " |      Delete snapshot for a given collection.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          snapshot_name: Snapshot id\n",
            " |          wait: Await for the snapshot to be deleted.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when the snapshot is deleted\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |      \n",
            " |      Returns:\n",
            " |          True if snapshot was deleted\n",
            " |  \n",
            " |  delete_vectors(self, collection_name: str, vectors: Sequence[str], points: Union[List[Union[int, str, points_pb2.PointId]], qdrant_client.http.models.models.Filter, points_pb2.Filter, qdrant_client.http.models.models.PointIdsList, qdrant_client.http.models.models.FilterSelector, points_pb2.PointsSelector], wait: bool = True, ordering: Optional[qdrant_client.http.models.models.WriteOrdering] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, **kwargs: Any) -> qdrant_client.http.models.models.UpdateResult\n",
            " |      Delete specified vector from the collection. Does not affect payload.\n",
            " |      \n",
            " |      Args:\n",
            " |      \n",
            " |          collection_name (str): Name of the collection to delete vector from\n",
            " |          vectors: List of names of the vectors to delete. Use `\"\"` to delete the default vector. At least one vector should be specified.\n",
            " |          points (Point): Selects points based on list of IDs or filter\n",
            " |              Examples\n",
            " |      \n",
            " |              - `points=[1, 2, 3, \"cd3b53f0-11a7-449f-bc50-d06310e7ed90\"]`\n",
            " |              - `points=Filter(must=[FieldCondition(key='rand_number', range=Range(gte=0.7))])`\n",
            " |          wait (bool): Await for the results to be processed.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when all changes are applied\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |          ordering (Optional[WriteOrdering]): Define strategy for ordering of the points. Possible values:\n",
            " |      \n",
            " |              - `weak` (default) - write operations may be reordered, works faster\n",
            " |              - `medium` - write operations go through dynamically selected leader, may be inconsistent for a short period of time in case of leader change\n",
            " |              - `strong` - Write operations go through the permanent leader, consistent, but may be unavailable if leader is down\n",
            " |      \n",
            " |          shard_key_selector:\n",
            " |              Defines the shard groups that should be used to write updates into.\n",
            " |              If multiple shard_keys are provided, the update will be written to each of them.\n",
            " |              Only works for collections with `custom` sharding method.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation result\n",
            " |  \n",
            " |  discover(self, collection_name: str, target: Union[Annotated[int, Strict(strict=True)], Annotated[str, Strict(strict=True)], List[Annotated[float, Strict(strict=True)]], qdrant_client.http.models.models.SparseVector, points_pb2.TargetVector, NoneType] = None, context: Optional[Sequence[Union[qdrant_client.http.models.models.ContextExamplePair, points_pb2.ContextExamplePair]]] = None, query_filter: Union[qdrant_client.http.models.models.Filter, points_pb2.Filter, NoneType] = None, search_params: Union[qdrant_client.http.models.models.SearchParams, points_pb2.SearchParams, NoneType] = None, limit: int = 10, offset: int = 0, with_payload: Union[bool, List[str], qdrant_client.http.models.models.PayloadSelectorInclude, qdrant_client.http.models.models.PayloadSelectorExclude, points_pb2.WithPayloadSelector] = True, with_vectors: Union[bool, List[str]] = False, using: Optional[str] = None, lookup_from: Union[qdrant_client.http.models.models.LookupLocation, points_pb2.LookupLocation, NoneType] = None, consistency: Union[Annotated[int, Strict(strict=True)], qdrant_client.http.models.models.ReadConsistencyType, NoneType] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, timeout: Optional[int] = None, **kwargs: Any) -> List[qdrant_client.http.models.models.ScoredPoint]\n",
            " |      Use context and a target to find the most similar points, constrained by the context.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Collection to discover in\n",
            " |      \n",
            " |          target:\n",
            " |              Look for vectors closest to this.\n",
            " |      \n",
            " |              When using the target (with or without context), the integer part of the score represents the rank with respect to the context, while the decimal part of the score relates to the distance to the target.\n",
            " |      \n",
            " |          context:\n",
            " |              Pairs of { positive, negative } examples to constrain the search.\n",
            " |      \n",
            " |              When using only the context (without a target), a special search - called context search - is performed where pairs of points are used to generate a loss that guides the search towards the zone where most positive examples overlap. This means that the score minimizes the scenario of finding a point closer to a negative than to a positive part of a pair.\n",
            " |      \n",
            " |              Since the score of a context relates to loss, the maximum score a point can get is 0.0, and it becomes normal that many points can have a score of 0.0.\n",
            " |      \n",
            " |              For discovery search (when including a target), the context part of the score for each pair is calculated +1 if the point is closer to a positive than to a negative part of a pair, and -1 otherwise.\n",
            " |      \n",
            " |          query_filter:\n",
            " |              Look only for points which satisfies this conditions\n",
            " |      \n",
            " |          search_params:\n",
            " |              Additional search params\n",
            " |      \n",
            " |          limit:\n",
            " |              Max number of result to return\n",
            " |      \n",
            " |          offset:\n",
            " |              Offset of the first result to return. May be used to paginate results. Note: large offset values may cause performance issues.\n",
            " |      \n",
            " |          with_payload:\n",
            " |              Select which payload to return with the response. Default: None\n",
            " |      \n",
            " |          with_vectors:\n",
            " |              Whether to return the point vector with the result?\n",
            " |      \n",
            " |          using:\n",
            " |              Define which vector to use for recommendation, if not specified - try to use default vector.\n",
            " |      \n",
            " |          lookup_from:\n",
            " |              The location used to lookup vectors. If not specified - use current collection. Note: the other collection should have the same vector size as the current collection.\n",
            " |      \n",
            " |          consistency:\n",
            " |              Read consistency of the search. Defines how many replicas should be queried before returning the result. Values:\n",
            " |      \n",
            " |              - int - number of replicas to query, values should present in all queried replicas\n",
            " |              - 'majority' - query all replicas, but return values present in the majority of replicas\n",
            " |              - 'quorum' - query the majority of replicas, return values present in all of them\n",
            " |              - 'all' - query all replicas, and return values present in all replicas\n",
            " |      \n",
            " |          shard_key_selector:\n",
            " |              This parameter allows to specify which shards should be queried.\n",
            " |              If `None` - query all shards. Only works for collections with `custom` sharding method.\n",
            " |      \n",
            " |          timeout:\n",
            " |              Overrides global timeout for this search. Unit is seconds.\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of discovered points with discovery or context scores, accordingly.\n",
            " |  \n",
            " |  discover_batch(self, collection_name: str, requests: Sequence[Union[qdrant_client.http.models.models.DiscoverRequest, points_pb2.DiscoverPoints]], consistency: Union[Annotated[int, Strict(strict=True)], qdrant_client.http.models.models.ReadConsistencyType, NoneType] = None, timeout: Optional[int] = None, **kwargs: Any) -> List[List[qdrant_client.http.models.models.ScoredPoint]]\n",
            " |  \n",
            " |  get_aliases(self, **kwargs: Any) -> qdrant_client.http.models.models.CollectionsAliasesResponse\n",
            " |      Get all aliases\n",
            " |      \n",
            " |      Returns:\n",
            " |          All aliases of all collections\n",
            " |  \n",
            " |  get_collection(self, collection_name: str, **kwargs: Any) -> qdrant_client.http.models.models.CollectionInfo\n",
            " |      Get detailed information about specified existing collection\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |      \n",
            " |      Returns:\n",
            " |          Detailed information about the collection\n",
            " |  \n",
            " |  get_collection_aliases(self, collection_name: str, **kwargs: Any) -> qdrant_client.http.models.models.CollectionsAliasesResponse\n",
            " |      Get collection aliases\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |      \n",
            " |      Returns:\n",
            " |          Collection aliases\n",
            " |  \n",
            " |  get_collections(self, **kwargs: Any) -> qdrant_client.http.models.models.CollectionsResponse\n",
            " |      Get list name of all existing collections\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of the collections\n",
            " |  \n",
            " |  get_locks(self, **kwargs: Any) -> qdrant_client.http.models.models.LocksOption\n",
            " |      Get current locks state.\n",
            " |  \n",
            " |  list_full_snapshots(self, **kwargs: Any) -> List[qdrant_client.http.models.models.SnapshotDescription]\n",
            " |      List all snapshots for a whole storage\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of snapshots\n",
            " |  \n",
            " |  list_shard_snapshots(self, collection_name: str, shard_id: int, **kwargs: Any) -> List[qdrant_client.http.models.models.SnapshotDescription]\n",
            " |      List all snapshots of a given shard\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          shard_id: Index of the shard\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of snapshots\n",
            " |  \n",
            " |  list_snapshots(self, collection_name: str, **kwargs: Any) -> List[qdrant_client.http.models.models.SnapshotDescription]\n",
            " |      List all snapshots for a given collection.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of snapshots\n",
            " |  \n",
            " |  lock_storage(self, reason: str, **kwargs: Any) -> qdrant_client.http.models.models.LocksOption\n",
            " |      Lock storage for writing.\n",
            " |  \n",
            " |  migrate(self, dest_client: qdrant_client.client_base.QdrantBase, collection_names: Optional[List[str]] = None, batch_size: int = 100, recreate_on_collision: bool = False) -> None\n",
            " |      Migrate data from one Qdrant instance to another.\n",
            " |      \n",
            " |      Args:\n",
            " |          dest_client: Destination Qdrant instance either in local or remote mode\n",
            " |          collection_names: List of collection names to migrate. If None - migrate all collections\n",
            " |          batch_size: Batch size to be in scroll and upsert operations during migration\n",
            " |          recreate_on_collision: If True - recreate collection on destination if it already exists, otherwise\n",
            " |              raise ValueError exception\n",
            " |  \n",
            " |  overwrite_payload(self, collection_name: str, payload: Dict[str, Any], points: Union[List[Union[int, str, points_pb2.PointId]], qdrant_client.http.models.models.Filter, points_pb2.Filter, qdrant_client.http.models.models.PointIdsList, qdrant_client.http.models.models.FilterSelector, points_pb2.PointsSelector], wait: bool = True, ordering: Optional[qdrant_client.http.models.models.WriteOrdering] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, **kwargs: Any) -> qdrant_client.http.models.models.UpdateResult\n",
            " |      Overwrites payload of the specified points\n",
            " |      After this operation is applied, only the specified payload will be present in the point.\n",
            " |      The existing payload, even if the key is not specified in the payload, will be deleted.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      `Set payload`::\n",
            " |      \n",
            " |          # Overwrite payload value with key `\"key\"` to points 1, 2, 3.\n",
            " |          # If any other valid payload value exists - it will be deleted\n",
            " |          qdrant_client.overwrite_payload(\n",
            " |              collection_name=\"test_collection\",\n",
            " |              wait=True,\n",
            " |              payload={\n",
            " |                  \"key\": \"value\"\n",
            " |              },\n",
            " |              points=[1,2,3]\n",
            " |          )\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          wait: Await for the results to be processed.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when all changes are applied\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |          payload: Key-value pairs of payload to assign\n",
            " |          points: List of affected points, filter or points selector.\n",
            " |              Example\n",
            " |                  - `points=[1, 2, 3, \"cd3b53f0-11a7-449f-bc50-d06310e7ed90\"]`\n",
            " |                  - `points=Filter(must=[FieldCondition(key='rand_number', range=Range(gte=0.7))])`\n",
            " |      \n",
            " |          ordering (Optional[WriteOrdering]): Define strategy for ordering of the points. Possible values:\n",
            " |      \n",
            " |              - `weak` (default) - write operations may be reordered, works faster\n",
            " |              - `medium` - write operations go through dynamically selected leader, may be inconsistent for a short period of time in case of leader change\n",
            " |              - `strong` - Write operations go through the permanent leader, consistent, but may be unavailable if leader is down\n",
            " |      \n",
            " |          shard_key_selector:\n",
            " |              Defines the shard groups that should be used to write updates into.\n",
            " |              If multiple shard_keys are provided, the update will be written to each of them.\n",
            " |              Only works for collections with `custom` sharding method.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation result\n",
            " |  \n",
            " |  recommend(self, collection_name: str, positive: Optional[Sequence[Union[Annotated[int, Strict(strict=True)], Annotated[str, Strict(strict=True)], List[Annotated[float, Strict(strict=True)]], qdrant_client.http.models.models.SparseVector]]] = None, negative: Optional[Sequence[Union[Annotated[int, Strict(strict=True)], Annotated[str, Strict(strict=True)], List[Annotated[float, Strict(strict=True)]], qdrant_client.http.models.models.SparseVector]]] = None, query_filter: Union[qdrant_client.http.models.models.Filter, points_pb2.Filter, NoneType] = None, search_params: Union[qdrant_client.http.models.models.SearchParams, points_pb2.SearchParams, NoneType] = None, limit: int = 10, offset: int = 0, with_payload: Union[bool, List[str], qdrant_client.http.models.models.PayloadSelectorInclude, qdrant_client.http.models.models.PayloadSelectorExclude, points_pb2.WithPayloadSelector] = True, with_vectors: Union[bool, List[str]] = False, score_threshold: Optional[float] = None, using: Optional[str] = None, lookup_from: Union[qdrant_client.http.models.models.LookupLocation, points_pb2.LookupLocation, NoneType] = None, strategy: Optional[qdrant_client.http.models.models.RecommendStrategy] = None, consistency: Union[Annotated[int, Strict(strict=True)], qdrant_client.http.models.models.ReadConsistencyType, NoneType] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, timeout: Optional[int] = None, **kwargs: Any) -> List[qdrant_client.http.models.models.ScoredPoint]\n",
            " |      Recommend points: search for similar points based on already stored in Qdrant examples.\n",
            " |      \n",
            " |      Provide IDs of the stored points, and Qdrant will perform search based on already existing vectors.\n",
            " |      This functionality is especially useful for recommendation over existing collection of points.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Collection to search in\n",
            " |          positive:\n",
            " |              List of stored point IDs or vectors, which should be used as reference for similarity search.\n",
            " |              If there is only one example - this request is equivalent to the regular search with vector of that\n",
            " |              point.\n",
            " |              If there are more than one example, Qdrant will attempt to search for similar to all of them.\n",
            " |              Recommendation for multiple vectors is experimental.\n",
            " |              Its behaviour may change depending on selected strategy.\n",
            " |          negative:\n",
            " |              List of stored point IDs or vectors, which should be dissimilar to the search result.\n",
            " |              Negative examples is an experimental functionality.\n",
            " |              Its behaviour may change depending on selected strategy.\n",
            " |          query_filter:\n",
            " |              - Exclude vectors which doesn't fit given conditions.\n",
            " |              - If `None` - search among all vectors\n",
            " |          search_params: Additional search params\n",
            " |          limit: How many results return\n",
            " |          offset:\n",
            " |              Offset of the first result to return.\n",
            " |              May be used to paginate results.\n",
            " |              Note: large offset values may cause performance issues.\n",
            " |          with_payload:\n",
            " |              - Specify which stored payload should be attached to the result.\n",
            " |              - If `True` - attach all payload\n",
            " |              - If `False` - do not attach any payload\n",
            " |              - If List of string - include only specified fields\n",
            " |              - If `PayloadSelector` - use explicit rules\n",
            " |          with_vectors:\n",
            " |              - If `True` - Attach stored vector to the search result.\n",
            " |              - If `False` - Do not attach vector.\n",
            " |              - If List of string - include only specified fields\n",
            " |              - Default: `False`\n",
            " |          score_threshold:\n",
            " |              Define a minimal score threshold for the result.\n",
            " |              If defined, less similar results will not be returned.\n",
            " |              Score of the returned result might be higher or smaller than the threshold depending\n",
            " |              on the Distance function used.\n",
            " |              E.g. for cosine similarity only higher scores will be returned.\n",
            " |          using:\n",
            " |              Name of the vectors to use for recommendations.\n",
            " |              If `None` - use default vectors.\n",
            " |          lookup_from:\n",
            " |              Defines a location (collection and vector field name), used to lookup vectors for recommendations.\n",
            " |              If `None` - use current collection will be used.\n",
            " |          consistency:\n",
            " |              Read consistency of the search. Defines how many replicas should be queried before returning the result. Values:\n",
            " |      \n",
            " |              - int - number of replicas to query, values should present in all queried replicas\n",
            " |              - 'majority' - query all replicas, but return values present in the majority of replicas\n",
            " |              - 'quorum' - query the majority of replicas, return values present in all of them\n",
            " |              - 'all' - query all replicas, and return values present in all replicas\n",
            " |          shard_key_selector:\n",
            " |              This parameter allows to specify which shards should be queried.\n",
            " |              If `None` - query all shards. Only works for collections with `custom` sharding method.\n",
            " |          strategy:\n",
            " |              Strategy to use for recommendation.\n",
            " |              Strategy defines how to combine multiple examples into a recommendation query.\n",
            " |              Possible values:\n",
            " |      \n",
            " |              - 'average_vector' - calculates average vector of all examples and uses it for search\n",
            " |              - 'best_score' - finds the result which is closer to positive examples and further from negative\n",
            " |          timeout:\n",
            " |              Overrides global timeout for this search. Unit is seconds.\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of recommended points with similarity scores.\n",
            " |  \n",
            " |  recommend_batch(self, collection_name: str, requests: Sequence[Union[qdrant_client.http.models.models.RecommendRequest, points_pb2.RecommendPoints]], consistency: Union[Annotated[int, Strict(strict=True)], qdrant_client.http.models.models.ReadConsistencyType, NoneType] = None, timeout: Optional[int] = None, **kwargs: Any) -> List[List[qdrant_client.http.models.models.ScoredPoint]]\n",
            " |      Perform multiple recommend requests in batch mode\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          requests: List of recommend requests\n",
            " |          consistency:\n",
            " |              Read consistency of the search. Defines how many replicas should be queried before returning the result. Values:\n",
            " |      \n",
            " |              - int - number of replicas to query, values should present in all queried replicas\n",
            " |              - 'majority' - query all replicas, but return values present in the majority of replicas\n",
            " |              - 'quorum' - query the majority of replicas, return values present in all of them\n",
            " |              - 'all' - query all replicas, and return values present in all replicas\n",
            " |          timeout:\n",
            " |              Overrides global timeout for this search. Unit is seconds.\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of recommend responses\n",
            " |  \n",
            " |  recommend_groups(self, collection_name: str, group_by: str, positive: Optional[Sequence[Union[Annotated[int, Strict(strict=True)], Annotated[str, Strict(strict=True)], List[Annotated[float, Strict(strict=True)]], qdrant_client.http.models.models.SparseVector]]] = None, negative: Optional[Sequence[Union[Annotated[int, Strict(strict=True)], Annotated[str, Strict(strict=True)], List[Annotated[float, Strict(strict=True)]], qdrant_client.http.models.models.SparseVector]]] = None, query_filter: Union[qdrant_client.http.models.models.Filter, points_pb2.Filter, NoneType] = None, search_params: Union[qdrant_client.http.models.models.SearchParams, points_pb2.SearchParams, NoneType] = None, limit: int = 10, group_size: int = 1, score_threshold: Optional[float] = None, with_payload: Union[bool, Sequence[str], qdrant_client.http.models.models.PayloadSelectorInclude, qdrant_client.http.models.models.PayloadSelectorExclude, points_pb2.WithPayloadSelector] = True, with_vectors: Union[bool, Sequence[str]] = False, using: Optional[str] = None, lookup_from: Union[qdrant_client.http.models.models.LookupLocation, points_pb2.LookupLocation, NoneType] = None, with_lookup: Union[Annotated[str, Strict(strict=True)], qdrant_client.http.models.models.WithLookup, NoneType] = None, strategy: Optional[qdrant_client.http.models.models.RecommendStrategy] = None, consistency: Union[Annotated[int, Strict(strict=True)], qdrant_client.http.models.models.ReadConsistencyType, NoneType] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, timeout: Optional[int] = None, **kwargs: Any) -> qdrant_client.http.models.models.GroupsResult\n",
            " |      Recommend point groups: search for similar points based on already stored in Qdrant examples\n",
            " |      and groups by payload field.\n",
            " |      \n",
            " |      Recommend best matches for given stored examples grouped by the value of payload field.\n",
            " |      Useful to obtain most relevant results for each category, deduplicate results,\n",
            " |      finding the best representation vector for the same entity.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Collection to search in\n",
            " |          positive:\n",
            " |              List of stored point IDs or vectors, which should be used as reference for similarity search.\n",
            " |              If there is only one example - this request is equivalent to the regular search with vector of that\n",
            " |              point.\n",
            " |              If there are more than one example, Qdrant will attempt to search for similar to all of them.\n",
            " |              Recommendation for multiple vectors is experimental.\n",
            " |              Its behaviour may change depending on selected strategy.\n",
            " |          negative:\n",
            " |              List of stored point IDs or vectors, which should be dissimilar to the search result.\n",
            " |              Negative examples is an experimental functionality.\n",
            " |              Its behaviour may change depending on selected strategy.\n",
            " |          group_by: Name of the payload field to group by.\n",
            " |              Field must be of type \"keyword\" or \"integer\".\n",
            " |              Nested fields are specified using dot notation, e.g. \"nested_field.subfield\".\n",
            " |          query_filter:\n",
            " |              - Exclude vectors which doesn't fit given conditions.\n",
            " |              - If `None` - search among all vectors\n",
            " |          search_params: Additional search params\n",
            " |          limit: How many groups return\n",
            " |          group_size: How many results return for each group\n",
            " |          with_payload:\n",
            " |              - Specify which stored payload should be attached to the result.\n",
            " |              - If `True` - attach all payload\n",
            " |              - If `False` - do not attach any payload\n",
            " |              - If List of string - include only specified fields\n",
            " |              - If `PayloadSelector` - use explicit rules\n",
            " |          with_vectors:\n",
            " |              - If `True` - Attach stored vector to the search result.\n",
            " |              - If `False` - Do not attach vector.\n",
            " |              - If List of string - include only specified fields\n",
            " |              - Default: `False`\n",
            " |          score_threshold:\n",
            " |              Define a minimal score threshold for the result.\n",
            " |              If defined, less similar results will not be returned.\n",
            " |              Score of the returned result might be higher or smaller than the threshold depending\n",
            " |              on the Distance function used.\n",
            " |              E.g. for cosine similarity only higher scores will be returned.\n",
            " |          using:\n",
            " |              Name of the vectors to use for recommendations.\n",
            " |              If `None` - use default vectors.\n",
            " |          lookup_from:\n",
            " |              Defines a location (collection and vector field name), used to lookup vectors for recommendations.\n",
            " |              If `None` - use current collection will be used.\n",
            " |          with_lookup:\n",
            " |              Look for points in another collection using the group ids.\n",
            " |              If specified, each group will contain a record from the specified collection\n",
            " |              with the same id as the group id. In addition, the parameter allows to specify\n",
            " |              which parts of the record should be returned, like in `with_payload` and `with_vectors` parameters.\n",
            " |          consistency:\n",
            " |              Read consistency of the search. Defines how many replicas should be queried before returning the result. Values:\n",
            " |      \n",
            " |              - int - number of replicas to query, values should present in all queried replicas\n",
            " |              - 'majority' - query all replicas, but return values present in the majority of replicas\n",
            " |              - 'quorum' - query the majority of replicas, return values present in all of them\n",
            " |              - 'all' - query all replicas, and return values present in all replicas\n",
            " |          shard_key_selector:\n",
            " |              This parameter allows to specify which shards should be queried.\n",
            " |              If `None` - query all shards. Only works for collections with `custom` sharding method.\n",
            " |          strategy:\n",
            " |              Strategy to use for recommendation.\n",
            " |              Strategy defines how to combine multiple examples into a recommendation query.\n",
            " |              Possible values:\n",
            " |      \n",
            " |              - 'average_vector' - calculates average vector of all examples and uses it for search\n",
            " |              - 'best_score' - finds the result which is closer to positive examples and further from negative\n",
            " |          timeout:\n",
            " |              Overrides global timeout for this search. Unit is seconds.\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of groups with not more than `group_size` hits in each group.\n",
            " |          Each group also contains an id of the group, which is the value of the payload field.\n",
            " |  \n",
            " |  recover_shard_snapshot(self, collection_name: str, shard_id: int, location: str, priority: Optional[qdrant_client.http.models.models.SnapshotPriority] = None, wait: bool = True, **kwargs: Any) -> Optional[bool]\n",
            " |      Recover shard from snapshot.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          shard_id: Index of the shard\n",
            " |          location: URL of the snapshot\n",
            " |              Example:\n",
            " |              - URL `http://localhost:8080/collections/my_collection/snapshots/my_snapshot`\n",
            " |          priority: Defines source of truth for snapshot recovery\n",
            " |      \n",
            " |              - `replica` (default) means - prefer existing data over the snapshot\n",
            " |              - `no_sync` means - do not sync shard with other shards\n",
            " |              - `snapshot` means - prefer snapshot data over the current state\n",
            " |          wait: Await for the recovery to be done.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when the recovery is done\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |      \n",
            " |      Returns:\n",
            " |          True if snapshot was recovered\n",
            " |  \n",
            " |  recover_snapshot(self, collection_name: str, location: str, priority: Optional[qdrant_client.http.models.models.SnapshotPriority] = None, wait: bool = True, **kwargs: Any) -> Optional[bool]\n",
            " |      Recover collection from snapshot.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          location: URL of the snapshot\n",
            " |              Example:\n",
            " |              - URL `http://localhost:8080/collections/my_collection/snapshots/my_snapshot`\n",
            " |              - Local path `file:///qdrant/snapshots/test_collection/test_collection-6194298859870377-2023-11-09-15-17-51.snapshot`\n",
            " |      \n",
            " |          priority: Defines source of truth for snapshot recovery\n",
            " |      \n",
            " |              - `replica` (default) means - prefer existing data over the snapshot\n",
            " |              - `no_sync` means - do not sync shard with other shards\n",
            " |              - `snapshot` means - prefer snapshot data over the current state\n",
            " |      \n",
            " |          wait: Await for the recovery to be done.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when the recovery is done\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |      \n",
            " |      Returns:\n",
            " |          True if snapshot was recovered\n",
            " |  \n",
            " |  recreate_collection(self, collection_name: str, vectors_config: Union[qdrant_client.http.models.models.VectorParams, Mapping[str, qdrant_client.http.models.models.VectorParams]], sparse_vectors_config: Optional[Mapping[str, qdrant_client.http.models.models.SparseVectorParams]] = None, shard_number: Optional[int] = None, sharding_method: Optional[qdrant_client.http.models.models.ShardingMethod] = None, replication_factor: Optional[int] = None, write_consistency_factor: Optional[int] = None, on_disk_payload: Optional[bool] = None, hnsw_config: Union[qdrant_client.http.models.models.HnswConfigDiff, collections_pb2.HnswConfigDiff, NoneType] = None, optimizers_config: Union[qdrant_client.http.models.models.OptimizersConfigDiff, collections_pb2.OptimizersConfigDiff, NoneType] = None, wal_config: Union[qdrant_client.http.models.models.WalConfigDiff, collections_pb2.WalConfigDiff, NoneType] = None, quantization_config: Union[qdrant_client.http.models.models.ScalarQuantization, qdrant_client.http.models.models.ProductQuantization, qdrant_client.http.models.models.BinaryQuantization, collections_pb2.QuantizationConfig, NoneType] = None, init_from: Union[qdrant_client.http.models.models.InitFrom, str, NoneType] = None, timeout: Optional[int] = None, **kwargs: Any) -> bool\n",
            " |      Delete and create empty collection with given parameters\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection to recreate\n",
            " |          vectors_config:\n",
            " |              Configuration of the vector storage. Vector params contains size and distance for the vector storage.\n",
            " |              If dict is passed, service will create a vector storage for each key in the dict.\n",
            " |              If single VectorParams is passed, service will create a single anonymous vector storage.\n",
            " |          sparse_vectors_config:\n",
            " |              Configuration of the sparse vector storage.\n",
            " |              The service will create a sparse vector storage for each key in the dict.\n",
            " |          shard_number: Number of shards in collection. Default is 1, minimum is 1.\n",
            " |          sharding_method:\n",
            " |              Defines strategy for shard creation.\n",
            " |              Option `auto` (default) creates defined number of shards automatically.\n",
            " |              Data will be distributed between shards automatically.\n",
            " |              After creation, shards could be additionally replicated, but new shards could not be created.\n",
            " |              Option `custom` allows to create shards manually, each shard should be created with assigned\n",
            " |              unique `shard_key`. Data will be distributed between based on `shard_key` value.\n",
            " |          replication_factor:\n",
            " |              Replication factor for collection. Default is 1, minimum is 1.\n",
            " |              Defines how many copies of each shard will be created.\n",
            " |              Have effect only in distributed mode.\n",
            " |          write_consistency_factor:\n",
            " |              Write consistency factor for collection. Default is 1, minimum is 1.\n",
            " |              Defines how many replicas should apply the operation for us to consider it successful.\n",
            " |              Increasing this number will make the collection more resilient to inconsistencies, but will\n",
            " |              also make it fail if not enough replicas are available.\n",
            " |              Does not have any performance impact.\n",
            " |              Have effect only in distributed mode.\n",
            " |          on_disk_payload:\n",
            " |              If true - point`s payload will not be stored in memory.\n",
            " |              It will be read from the disk every time it is requested.\n",
            " |              This setting saves RAM by (slightly) increasing the response time.\n",
            " |              Note: those payload values that are involved in filtering and are indexed - remain in RAM.\n",
            " |          hnsw_config: Params for HNSW index\n",
            " |          optimizers_config: Params for optimizer\n",
            " |          wal_config: Params for Write-Ahead-Log\n",
            " |          quantization_config: Params for quantization, if None - quantization will be disabled\n",
            " |          init_from: Use data stored in another collection to initialize this collection\n",
            " |          timeout:\n",
            " |              Wait for operation commit timeout in seconds.\n",
            " |              If timeout is reached - request will return with service error.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation result\n",
            " |  \n",
            " |  retrieve(self, collection_name: str, ids: Sequence[Union[int, str, points_pb2.PointId]], with_payload: Union[bool, Sequence[str], qdrant_client.http.models.models.PayloadSelectorInclude, qdrant_client.http.models.models.PayloadSelectorExclude, points_pb2.WithPayloadSelector] = True, with_vectors: Union[bool, Sequence[str]] = False, consistency: Union[Annotated[int, Strict(strict=True)], qdrant_client.http.models.models.ReadConsistencyType, NoneType] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, **kwargs: Any) -> List[qdrant_client.http.models.models.Record]\n",
            " |      Retrieve stored points by IDs\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection to lookup in\n",
            " |          ids: list of IDs to lookup\n",
            " |          with_payload:\n",
            " |              - Specify which stored payload should be attached to the result.\n",
            " |              - If `True` - attach all payload\n",
            " |              - If `False` - do not attach any payload\n",
            " |              - If List of string - include only specified fields\n",
            " |              - If `PayloadSelector` - use explicit rules\n",
            " |          with_vectors:\n",
            " |              - If `True` - Attach stored vector to the search result.\n",
            " |              - If `False` - Do not attach vector.\n",
            " |              - If List of string - Attach only specified vectors.\n",
            " |              - Default: `False`\n",
            " |          consistency:\n",
            " |              Read consistency of the search. Defines how many replicas should be queried before returning the result. Values:\n",
            " |      \n",
            " |              - int - number of replicas to query, values should present in all queried replicas\n",
            " |              - 'majority' - query all replicas, but return values present in the majority of replicas\n",
            " |              - 'quorum' - query the majority of replicas, return values present in all of them\n",
            " |              - 'all' - query all replicas, and return values present in all replicas\n",
            " |      \n",
            " |          shard_key_selector:\n",
            " |              This parameter allows to specify which shards should be queried.\n",
            " |              If `None` - query all shards. Only works for collections with `custom` sharding method.\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of points\n",
            " |  \n",
            " |  scroll(self, collection_name: str, scroll_filter: Union[qdrant_client.http.models.models.Filter, points_pb2.Filter, NoneType] = None, limit: int = 10, order_by: Union[Annotated[str, Strict(strict=True)], qdrant_client.http.models.models.OrderBy, points_pb2.OrderBy, NoneType] = None, offset: Union[int, str, points_pb2.PointId, NoneType] = None, with_payload: Union[bool, Sequence[str], qdrant_client.http.models.models.PayloadSelectorInclude, qdrant_client.http.models.models.PayloadSelectorExclude, points_pb2.WithPayloadSelector] = True, with_vectors: Union[bool, Sequence[str]] = False, consistency: Union[Annotated[int, Strict(strict=True)], qdrant_client.http.models.models.ReadConsistencyType, NoneType] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, **kwargs: Any) -> Tuple[List[qdrant_client.http.models.models.Record], Union[int, str, points_pb2.PointId, NoneType]]\n",
            " |      Scroll over all (matching) points in the collection.\n",
            " |      \n",
            " |      This method provides a way to iterate over all stored points with some optional filtering condition.\n",
            " |      Scroll does not apply any similarity estimations, it will return points sorted by id in ascending order.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          scroll_filter: If provided - only returns points matching filtering conditions\n",
            " |          limit: How many points to return\n",
            " |          order_by: Order the records by a payload key. If `None` - order by id\n",
            " |          offset: If provided - skip points with ids less than given `offset`\n",
            " |          with_payload:\n",
            " |              - Specify which stored payload should be attached to the result.\n",
            " |              - If `True` - attach all payload\n",
            " |              - If `False` - do not attach any payload\n",
            " |              - If List of string - include only specified fields\n",
            " |              - If `PayloadSelector` - use explicit rules\n",
            " |          with_vectors:\n",
            " |              - If `True` - Attach stored vector to the search result.\n",
            " |              - If `False` (default) - Do not attach vector.\n",
            " |              - If List of string - include only specified fields\n",
            " |          consistency:\n",
            " |              Read consistency of the search. Defines how many replicas should be queried before returning the result. Values:\n",
            " |      \n",
            " |              - int - number of replicas to query, values should present in all queried replicas\n",
            " |              - 'majority' - query all replicas, but return values present in the majority of replicas\n",
            " |              - 'quorum' - query the majority of replicas, return values present in all of them\n",
            " |              - 'all' - query all replicas, and return values present in all replicas\n",
            " |      \n",
            " |          shard_key_selector:\n",
            " |              This parameter allows to specify which shards should be queried.\n",
            " |              If `None` - query all shards. Only works for collections with `custom` sharding method.\n",
            " |      \n",
            " |      Returns:\n",
            " |          A pair of (List of points) and (optional offset for the next scroll request).\n",
            " |          If next page offset is `None` - there is no more points in the collection to scroll.\n",
            " |  \n",
            " |  search(self, collection_name: str, query_vector: Union[numpy.ndarray[Any, numpy.dtype[Union[numpy.bool_, numpy.int8, numpy.int16, numpy.int32, numpy.int64, numpy.uint8, numpy.uint16, numpy.uint32, numpy.uint64, numpy.float16, numpy.float32, numpy.float64, numpy.longdouble]]], Sequence[float], Tuple[str, List[float]], qdrant_client.http.models.models.NamedVector, qdrant_client.http.models.models.NamedSparseVector], query_filter: Union[qdrant_client.http.models.models.Filter, points_pb2.Filter, NoneType] = None, search_params: Union[qdrant_client.http.models.models.SearchParams, points_pb2.SearchParams, NoneType] = None, limit: int = 10, offset: Optional[int] = None, with_payload: Union[bool, Sequence[str], qdrant_client.http.models.models.PayloadSelectorInclude, qdrant_client.http.models.models.PayloadSelectorExclude, points_pb2.WithPayloadSelector] = True, with_vectors: Union[bool, Sequence[str]] = False, score_threshold: Optional[float] = None, append_payload: bool = True, consistency: Union[Annotated[int, Strict(strict=True)], qdrant_client.http.models.models.ReadConsistencyType, NoneType] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, timeout: Optional[int] = None, **kwargs: Any) -> List[qdrant_client.http.models.models.ScoredPoint]\n",
            " |      Search for closest vectors in collection taking into account filtering conditions\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Collection to search in\n",
            " |          query_vector:\n",
            " |              Search for vectors closest to this.\n",
            " |              Can be either a vector itself, or a named vector, or a named sparse vector, or a tuple of vector name and vector itself\n",
            " |          query_filter:\n",
            " |              - Exclude vectors which doesn't fit given conditions.\n",
            " |              - If `None` - search among all vectors\n",
            " |          search_params: Additional search params\n",
            " |          limit: How many results return\n",
            " |          offset:\n",
            " |              Offset of the first result to return.\n",
            " |              May be used to paginate results.\n",
            " |              Note: large offset values may cause performance issues.\n",
            " |          with_payload:\n",
            " |              - Specify which stored payload should be attached to the result.\n",
            " |              - If `True` - attach all payload\n",
            " |              - If `False` - do not attach any payload\n",
            " |              - If List of string - include only specified fields\n",
            " |              - If `PayloadSelector` - use explicit rules\n",
            " |          with_vectors:\n",
            " |              - If `True` - Attach stored vector to the search result.\n",
            " |              - If `False` - Do not attach vector.\n",
            " |              - If List of string - include only specified fields\n",
            " |              - Default: `False`\n",
            " |          score_threshold:\n",
            " |              Define a minimal score threshold for the result.\n",
            " |              If defined, less similar results will not be returned.\n",
            " |              Score of the returned result might be higher or smaller than the threshold depending\n",
            " |              on the Distance function used.\n",
            " |              E.g. for cosine similarity only higher scores will be returned.\n",
            " |          append_payload: Same as `with_payload`. Deprecated.\n",
            " |          consistency:\n",
            " |              Read consistency of the search. Defines how many replicas should be queried before returning the result. Values:\n",
            " |      \n",
            " |              - int - number of replicas to query, values should present in all queried replicas\n",
            " |              - 'majority' - query all replicas, but return values present in the majority of replicas\n",
            " |              - 'quorum' - query the majority of replicas, return values present in all of them\n",
            " |              - 'all' - query all replicas, and return values present in all replicas\n",
            " |          shard_key_selector:\n",
            " |              This parameter allows to specify which shards should be queried.\n",
            " |              If `None` - query all shards. Only works for collections with `custom` sharding method.\n",
            " |          timeout:\n",
            " |              Overrides global timeout for this search. Unit is seconds.\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      `Search with filter`::\n",
            " |      \n",
            " |          qdrant.search(\n",
            " |              collection_name=\"test_collection\",\n",
            " |              query_vector=[1.0, 0.1, 0.2, 0.7],\n",
            " |              query_filter=Filter(\n",
            " |                  must=[\n",
            " |                      FieldCondition(\n",
            " |                          key='color',\n",
            " |                          range=Match(\n",
            " |                              value=\"red\"\n",
            " |                          )\n",
            " |                      )\n",
            " |                  ]\n",
            " |              )\n",
            " |          )\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of found close points with similarity scores.\n",
            " |  \n",
            " |  search_batch(self, collection_name: str, requests: Sequence[Union[qdrant_client.http.models.models.SearchRequest, points_pb2.SearchPoints]], timeout: Optional[int] = None, consistency: Union[Annotated[int, Strict(strict=True)], qdrant_client.http.models.models.ReadConsistencyType, NoneType] = None, **kwargs: Any) -> List[List[qdrant_client.http.models.models.ScoredPoint]]\n",
            " |      Search for points in multiple collections\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          requests: List of search requests\n",
            " |          consistency:\n",
            " |              Read consistency of the search. Defines how many replicas should be queried before returning the result. Values:\n",
            " |      \n",
            " |              - int - number of replicas to query, values should present in all queried replicas\n",
            " |              - 'majority' - query all replicas, but return values present in the majority of replicas\n",
            " |              - 'quorum' - query the majority of replicas, return values present in all of them\n",
            " |              - 'all' - query all replicas, and return values present in all replicas\n",
            " |          timeout:\n",
            " |              Overrides global timeout for this search. Unit is seconds.\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of search responses\n",
            " |  \n",
            " |  search_groups(self, collection_name: str, query_vector: Union[numpy.ndarray[Any, numpy.dtype[Union[numpy.bool_, numpy.int8, numpy.int16, numpy.int32, numpy.int64, numpy.uint8, numpy.uint16, numpy.uint32, numpy.uint64, numpy.float16, numpy.float32, numpy.float64, numpy.longdouble]]], Sequence[float], Tuple[str, List[float]], qdrant_client.http.models.models.NamedVector, qdrant_client.http.models.models.NamedSparseVector], group_by: str, query_filter: Union[qdrant_client.http.models.models.Filter, points_pb2.Filter, NoneType] = None, search_params: Union[qdrant_client.http.models.models.SearchParams, points_pb2.SearchParams, NoneType] = None, limit: int = 10, group_size: int = 1, with_payload: Union[bool, Sequence[str], qdrant_client.http.models.models.PayloadSelectorInclude, qdrant_client.http.models.models.PayloadSelectorExclude, points_pb2.WithPayloadSelector] = True, with_vectors: Union[bool, Sequence[str]] = False, score_threshold: Optional[float] = None, with_lookup: Union[Annotated[str, Strict(strict=True)], qdrant_client.http.models.models.WithLookup, NoneType] = None, consistency: Union[Annotated[int, Strict(strict=True)], qdrant_client.http.models.models.ReadConsistencyType, NoneType] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, timeout: Optional[int] = None, **kwargs: Any) -> qdrant_client.http.models.models.GroupsResult\n",
            " |      Search for closest vectors grouped by payload field.\n",
            " |      \n",
            " |      Searches best matches for query vector grouped by the value of payload field.\n",
            " |      Useful to obtain most relevant results for each category, deduplicate results,\n",
            " |      finding the best representation vector for the same entity.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Collection to search in\n",
            " |          query_vector:\n",
            " |              Search for vectors closest to this.\n",
            " |              Can be either a vector itself, or a named vector, or a named sparse vector, or a tuple of vector name and vector itself\n",
            " |          group_by: Name of the payload field to group by.\n",
            " |              Field must be of type \"keyword\" or \"integer\".\n",
            " |              Nested fields are specified using dot notation, e.g. \"nested_field.subfield\".\n",
            " |          query_filter:\n",
            " |              - Exclude vectors which doesn't fit given conditions.\n",
            " |              - If `None` - search among all vectors\n",
            " |          search_params: Additional search params\n",
            " |          limit: How many groups return\n",
            " |          group_size: How many results return for each group\n",
            " |          with_payload:\n",
            " |              - Specify which stored payload should be attached to the result.\n",
            " |              - If `True` - attach all payload\n",
            " |              - If `False` - do not attach any payload\n",
            " |              - If List of string - include only specified fields\n",
            " |              - If `PayloadSelector` - use explicit rules\n",
            " |          with_vectors:\n",
            " |              - If `True` - Attach stored vector to the search result.\n",
            " |              - If `False` - Do not attach vector.\n",
            " |              - If List of string - include only specified fields\n",
            " |              - Default: `False`\n",
            " |          score_threshold: Minimal score threshold for the result.\n",
            " |              If defined, less similar results will not be returned.\n",
            " |              Score of the returned result might be higher or smaller than the threshold depending\n",
            " |              on the Distance function used.\n",
            " |              E.g. for cosine similarity only higher scores will be returned.\n",
            " |          with_lookup:\n",
            " |              Look for points in another collection using the group ids.\n",
            " |              If specified, each group will contain a record from the specified collection\n",
            " |              with the same id as the group id. In addition, the parameter allows to specify\n",
            " |              which parts of the record should be returned, like in `with_payload` and `with_vectors` parameters.\n",
            " |          consistency:\n",
            " |              Read consistency of the search. Defines how many replicas should be queried before returning the result.\n",
            " |              Values:\n",
            " |              - int - number of replicas to query, values should present in all queried replicas\n",
            " |              - 'majority' - query all replicas, but return values present in the majority of replicas\n",
            " |              - 'quorum' - query the majority of replicas, return values present in all of them\n",
            " |              - 'all' - query all replicas, and return values present in all replicas\n",
            " |          shard_key_selector:\n",
            " |              This parameter allows to specify which shards should be queried.\n",
            " |              If `None` - query all shards. Only works for collections with `custom` sharding method.\n",
            " |          timeout:\n",
            " |              Overrides global timeout for this search. Unit is seconds.\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of groups with not more than `group_size` hits in each group.\n",
            " |          Each group also contains an id of the group, which is the value of the payload field.\n",
            " |  \n",
            " |  set_payload(self, collection_name: str, payload: Dict[str, Any], points: Union[List[Union[int, str, points_pb2.PointId]], qdrant_client.http.models.models.Filter, points_pb2.Filter, qdrant_client.http.models.models.PointIdsList, qdrant_client.http.models.models.FilterSelector, points_pb2.PointsSelector], key: Optional[str] = None, wait: bool = True, ordering: Optional[qdrant_client.http.models.models.WriteOrdering] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, **kwargs: Any) -> qdrant_client.http.models.models.UpdateResult\n",
            " |      Modifies payload of the specified points\n",
            " |      \n",
            " |      Examples:\n",
            " |      \n",
            " |      `Set payload`::\n",
            " |      \n",
            " |          # Assign payload value with key `\"key\"` to points 1, 2, 3.\n",
            " |          # If payload value with specified key already exists - it will be overwritten\n",
            " |          qdrant_client.set_payload(\n",
            " |              collection_name=\"test_collection\",\n",
            " |              wait=True,\n",
            " |              payload={\n",
            " |                  \"key\": \"value\"\n",
            " |              },\n",
            " |              points=[1,2,3]\n",
            " |          )\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          wait: Await for the results to be processed.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when all changes are applied\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |          payload: Key-value pairs of payload to assign\n",
            " |          points: List of affected points, filter or points selector\n",
            " |              Example\n",
            " |      \n",
            " |                  - `points=[1, 2, 3, \"cd3b53f0-11a7-449f-bc50-d06310e7ed90\"]`\n",
            " |                  - `points=Filter(must=[FieldCondition(key='rand_number', range=Range(gte=0.7))])`\n",
            " |          ordering (Optional[WriteOrdering]): Define strategy for ordering of the points. Possible values:\n",
            " |      \n",
            " |              - `weak` (default) - write operations may be reordered, works faster\n",
            " |              - `medium` - write operations go through dynamically selected leader, may be inconsistent for a short period of time in case of leader change\n",
            " |              - `strong` - Write operations go through the permanent leader, consistent, but may be unavailable if leader is down\n",
            " |      \n",
            " |          shard_key_selector:\n",
            " |              Defines the shard groups that should be used to write updates into.\n",
            " |              If multiple shard_keys are provided, the update will be written to each of them.\n",
            " |              Only works for collections with `custom` sharding method.\n",
            " |      \n",
            " |          key: Path to the nested field in the payload to modify. If not specified - modify the root of the\n",
            " |              payload. E.g.:\n",
            " |      \n",
            " |              PointStruct(\n",
            " |                  id=42,\n",
            " |                  vector=[...],\n",
            " |                  payload={\n",
            " |                      \"recipe\": {\n",
            " |                          \"fruits\": {\"apple\": \"100g\"}\n",
            " |                      }\n",
            " |                  }\n",
            " |              )\n",
            " |      \n",
            " |              qdrant_client.set_payload(\n",
            " |                  ...,\n",
            " |                  payload = {\"cinnamon\": \"2g\"},\n",
            " |                  key = \"recipe.fruits\",\n",
            " |                  points=[42]\n",
            " |              )\n",
            " |      \n",
            " |              PointStruct(\n",
            " |                  id=42,\n",
            " |                  vector=[...],\n",
            " |                  payload={\n",
            " |                      \"recipe\": {\n",
            " |                          \"fruits\": {\n",
            " |                              \"apple\": \"100g\",\n",
            " |                              \"cinnamon\": \"2g\"\n",
            " |                          }\n",
            " |                      }\n",
            " |                  }\n",
            " |              )\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation result\n",
            " |  \n",
            " |  unlock_storage(self, **kwargs: Any) -> qdrant_client.http.models.models.LocksOption\n",
            " |      Unlock storage for writing.\n",
            " |  \n",
            " |  update_collection(self, collection_name: str, optimizers_config: Union[qdrant_client.http.models.models.OptimizersConfigDiff, collections_pb2.OptimizersConfigDiff, NoneType] = None, collection_params: Union[qdrant_client.http.models.models.CollectionParamsDiff, collections_pb2.CollectionParamsDiff, NoneType] = None, vectors_config: Union[Dict[str, ForwardRef('VectorParamsDiff')], collections_pb2.VectorsConfigDiff, NoneType] = None, hnsw_config: Union[qdrant_client.http.models.models.HnswConfigDiff, collections_pb2.HnswConfigDiff, NoneType] = None, quantization_config: Union[qdrant_client.http.models.models.ScalarQuantization, qdrant_client.http.models.models.ProductQuantization, qdrant_client.http.models.models.BinaryQuantization, qdrant_client.http.models.models.Disabled, collections_pb2.QuantizationConfigDiff, NoneType] = None, timeout: Optional[int] = None, sparse_vectors_config: Optional[Mapping[str, qdrant_client.http.models.models.SparseVectorParams]] = None, **kwargs: Any) -> bool\n",
            " |      Update parameters of the collection\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Name of the collection\n",
            " |          optimizers_config: Override for optimizer configuration\n",
            " |          collection_params: Override for collection parameters\n",
            " |          vectors_config: Override for vector-specific configuration\n",
            " |          hnsw_config: Override for HNSW index params\n",
            " |          quantization_config: Override for quantization params\n",
            " |          timeout:\n",
            " |              Wait for operation commit timeout in seconds.\n",
            " |              If timeout is reached - request will return with service error.\n",
            " |          sparse_vectors_config: Override for sparse vector-specific configuration\n",
            " |      Returns:\n",
            " |          Operation result\n",
            " |  \n",
            " |  update_collection_aliases(self, change_aliases_operations: Sequence[Union[qdrant_client.http.models.models.CreateAliasOperation, qdrant_client.http.models.models.RenameAliasOperation, qdrant_client.http.models.models.DeleteAliasOperation, collections_pb2.AliasOperations]], timeout: Optional[int] = None, **kwargs: Any) -> bool\n",
            " |      Operation for performing changes of collection aliases.\n",
            " |      \n",
            " |      Alias changes are atomic, meaning that no collection modifications can happen between alias operations.\n",
            " |      \n",
            " |      Args:\n",
            " |          change_aliases_operations: List of operations to perform\n",
            " |          timeout:\n",
            " |              Wait for operation commit timeout in seconds.\n",
            " |              If timeout is reached - request will return with service error.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation result\n",
            " |  \n",
            " |  update_vectors(self, collection_name: str, points: Sequence[qdrant_client.http.models.models.PointVectors], wait: bool = True, ordering: Optional[qdrant_client.http.models.models.WriteOrdering] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, **kwargs: Any) -> qdrant_client.http.models.models.UpdateResult\n",
            " |      Update specified vectors in the collection. Keeps payload and unspecified vectors unchanged.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name (str): Name of the collection to update vectors in\n",
            " |          points (Point): List of (id, vector) pairs to update. Vector might be a list of numbers or a dict of named vectors.\n",
            " |              Examples:\n",
            " |      \n",
            " |              - `PointVectors(id=1, vector=[1, 2, 3])`\n",
            " |              - `PointVectors(id=2, vector={'vector_1': [1, 2, 3], 'vector_2': [4, 5, 6]})`\n",
            " |      \n",
            " |          wait (bool): Await for the results to be processed.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when all changes are applied\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |      \n",
            " |          ordering (Optional[WriteOrdering]): Define strategy for ordering of the points. Possible values:\n",
            " |      \n",
            " |              - `weak` (default) - write operations may be reordered, works faster\n",
            " |              - `medium` - write operations go through dynamically selected leader, may be inconsistent for a short period of time in case of leader change\n",
            " |              - `strong` - Write operations go through the permanent leader, consistent, but may be unavailable if leader is down\n",
            " |      \n",
            " |          shard_key_selector:\n",
            " |              Defines the shard groups that should be used to write updates into.\n",
            " |              If multiple shard_keys are provided, the update will be written to each of them.\n",
            " |              Only works for collections with `custom` sharding method.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation Result(UpdateResult)\n",
            " |  \n",
            " |  upload_collection(self, collection_name: str, vectors: Union[Dict[str, numpy.ndarray[Any, numpy.dtype[Union[numpy.bool_, numpy.int8, numpy.int16, numpy.int32, numpy.int64, numpy.uint8, numpy.uint16, numpy.uint32, numpy.uint64, numpy.float16, numpy.float32, numpy.float64, numpy.longdouble]]]], numpy.ndarray[Any, numpy.dtype[Union[numpy.bool_, numpy.int8, numpy.int16, numpy.int32, numpy.int64, numpy.uint8, numpy.uint16, numpy.uint32, numpy.uint64, numpy.float16, numpy.float32, numpy.float64, numpy.longdouble]]], Iterable[Union[List[Annotated[float, Strict(strict=True)]], Dict[Annotated[str, Strict(strict=True)], Union[List[Annotated[float, Strict(strict=True)]], qdrant_client.http.models.models.SparseVector]]]]], payload: Optional[Iterable[Dict[Any, Any]]] = None, ids: Optional[Iterable[Union[int, str, points_pb2.PointId]]] = None, batch_size: int = 64, parallel: int = 1, method: Optional[str] = None, max_retries: int = 3, wait: bool = False, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, **kwargs: Any) -> None\n",
            " |      Upload vectors and payload to the collection.\n",
            " |      This method will perform automatic batching of the data.\n",
            " |      If you need to perform a single update, use `upsert` method.\n",
            " |      Note: use `upload_records` method if you want to upload multiple vectors with single payload.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name:  Name of the collection to upload to\n",
            " |          vectors: np.ndarray or an iterable over vectors to upload. Might be mmaped\n",
            " |          payload: Iterable of vectors payload, Optional, Default: None\n",
            " |          ids: Iterable of custom vectors ids, Optional, Default: None\n",
            " |          batch_size: How many vectors upload per-request, Default: 64\n",
            " |          parallel: Number of parallel processes of upload\n",
            " |          method: Start method for parallel processes, Default: forkserver\n",
            " |          max_retries: maximum number of retries in case of a failure\n",
            " |              during the upload of a batch\n",
            " |          wait:\n",
            " |              Await for the results to be applied on the server side.\n",
            " |              If `true`, each update request will explicitly wait for the confirmation of completion. Might be slower.\n",
            " |              If `false`, each update request will return immediately after the confirmation of receiving.\n",
            " |              Default: `false`\n",
            " |          shard_key_selector: Defines the shard groups that should be used to write updates into.\n",
            " |              If multiple shard_keys are provided, the update will be written to each of them.\n",
            " |              Only works for collections with `custom` sharding method.\n",
            " |  \n",
            " |  upload_points(self, collection_name: str, points: Iterable[qdrant_client.http.models.models.PointStruct], batch_size: int = 64, parallel: int = 1, method: Optional[str] = None, max_retries: int = 3, wait: bool = False, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, **kwargs: Any) -> None\n",
            " |      Upload points to the collection\n",
            " |      \n",
            " |      Similar to `upload_collection` method, but operates with points, rather than vector and payload individually.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name:  Name of the collection to upload to\n",
            " |          points: Iterator over points to upload\n",
            " |          batch_size: How many vectors upload per-request, Default: 64\n",
            " |          parallel: Number of parallel processes of upload\n",
            " |          method: Start method for parallel processes, Default: forkserver\n",
            " |          max_retries: maximum number of retries in case of a failure\n",
            " |              during the upload of a batch\n",
            " |          wait:\n",
            " |              Await for the results to be applied on the server side.\n",
            " |              If `true`, each update request will explicitly wait for the confirmation of completion. Might be slower.\n",
            " |              If `false`, each update request will return immediately after the confirmation of receiving.\n",
            " |              Default: `false`\n",
            " |          shard_key_selector: Defines the shard groups that should be used to write updates into.\n",
            " |              If multiple shard_keys are provided, the update will be written to each of them.\n",
            " |              Only works for collections with `custom` sharding method.\n",
            " |              This parameter overwrites shard keys written in the records.\n",
            " |  \n",
            " |  upload_records(self, collection_name: str, records: Iterable[qdrant_client.http.models.models.Record], batch_size: int = 64, parallel: int = 1, method: Optional[str] = None, max_retries: int = 3, wait: bool = False, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, **kwargs: Any) -> None\n",
            " |      Upload records to the collection\n",
            " |      \n",
            " |      Similar to `upload_collection` method, but operates with records, rather than vector and payload individually.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name:  Name of the collection to upload to\n",
            " |          records: Iterator over records to upload\n",
            " |          batch_size: How many vectors upload per-request, Default: 64\n",
            " |          parallel: Number of parallel processes of upload\n",
            " |          method: Start method for parallel processes, Default: forkserver\n",
            " |          max_retries: maximum number of retries in case of a failure\n",
            " |              during the upload of a batch\n",
            " |          wait:\n",
            " |              Await for the results to be applied on the server side.\n",
            " |              If `true`, each update request will explicitly wait for the confirmation of completion. Might be slower.\n",
            " |              If `false`, each update request will return immediately after the confirmation of receiving.\n",
            " |              Default: `false`\n",
            " |          shard_key_selector: Defines the shard groups that should be used to write updates into.\n",
            " |              If multiple shard_keys are provided, the update will be written to each of them.\n",
            " |              Only works for collections with `custom` sharding method.\n",
            " |              This parameter overwrites shard keys written in the records.\n",
            " |  \n",
            " |  upsert(self, collection_name: str, points: Union[qdrant_client.http.models.models.Batch, List[Union[qdrant_client.http.models.models.PointStruct, points_pb2.PointStruct]]], wait: bool = True, ordering: Optional[qdrant_client.http.models.models.WriteOrdering] = None, shard_key_selector: Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)], List[Union[Annotated[str, Strict(strict=True)], Annotated[int, Strict(strict=True)]]], NoneType] = None, **kwargs: Any) -> qdrant_client.http.models.models.UpdateResult\n",
            " |      Update or insert a new point into the collection.\n",
            " |      \n",
            " |      If point with given ID already exists - it will be overwritten.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name (str): To which collection to insert\n",
            " |          points (Point): Batch or list of points to insert\n",
            " |          wait (bool): Await for the results to be processed.\n",
            " |      \n",
            " |              - If `true`, result will be returned only when all changes are applied\n",
            " |              - If `false`, result will be returned immediately after the confirmation of receiving.\n",
            " |          ordering (Optional[WriteOrdering]): Define strategy for ordering of the points. Possible values:\n",
            " |      \n",
            " |              - `weak` (default) - write operations may be reordered, works faster\n",
            " |              - `medium` - write operations go through dynamically selected leader, may be inconsistent for a short period of time in case of leader change\n",
            " |              - `strong` - Write operations go through the permanent leader, consistent, but may be unavailable if leader is down\n",
            " |      \n",
            " |          shard_key_selector:\n",
            " |              Defines the shard groups that should be used to write updates into.\n",
            " |              If multiple shard_keys are provided, the update will be written to each of them.\n",
            " |              Only works for collections with `custom` sharding method.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Operation Result(UpdateResult)\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties defined here:\n",
            " |  \n",
            " |  async_grpc_collections\n",
            " |      gRPC client for collections methods\n",
            " |      \n",
            " |      Returns:\n",
            " |          An instance of raw gRPC client, generated from Protobuf\n",
            " |  \n",
            " |  async_grpc_points\n",
            " |      gRPC client for points methods\n",
            " |      \n",
            " |      Returns:\n",
            " |          An instance of raw gRPC client, generated from Protobuf\n",
            " |  \n",
            " |  grpc_collections\n",
            " |      gRPC client for collections methods\n",
            " |      \n",
            " |      Returns:\n",
            " |          An instance of raw gRPC client, generated from Protobuf\n",
            " |  \n",
            " |  grpc_points\n",
            " |      gRPC client for points methods\n",
            " |      \n",
            " |      Returns:\n",
            " |          An instance of raw gRPC client, generated from Protobuf\n",
            " |  \n",
            " |  http\n",
            " |      REST Client\n",
            " |      \n",
            " |      Returns:\n",
            " |          An instance of raw REST API client, generated from OpenAPI schema\n",
            " |  \n",
            " |  rest\n",
            " |      REST Client\n",
            " |      \n",
            " |      Returns:\n",
            " |          An instance of raw REST API client, generated from OpenAPI schema\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes defined here:\n",
            " |  \n",
            " |  __annotations__ = {}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Methods inherited from qdrant_client.qdrant_fastembed.QdrantFastembedMixin:\n",
            " |  \n",
            " |  add(self, collection_name: str, documents: Iterable[str], metadata: Optional[Iterable[Dict[str, Any]]] = None, ids: Optional[Iterable[Union[Annotated[int, Strict(strict=True)], Annotated[str, Strict(strict=True)]]]] = None, batch_size: int = 32, parallel: Optional[int] = None, **kwargs: Any) -> List[Union[str, int]]\n",
            " |      Adds text documents into qdrant collection.\n",
            " |      If collection does not exist, it will be created with default parameters.\n",
            " |      Metadata in combination with documents will be added as payload.\n",
            " |      Documents will be embedded using the specified embedding model.\n",
            " |      \n",
            " |      If you want to use your own vectors, use `upsert` method instead.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name (str):\n",
            " |              Name of the collection to add documents to.\n",
            " |          documents (Iterable[str]):\n",
            " |              List of documents to embed and add to the collection.\n",
            " |          metadata (Iterable[Dict[str, Any]], optional):\n",
            " |              List of metadata dicts. Defaults to None.\n",
            " |          ids (Iterable[models.ExtendedPointId], optional):\n",
            " |              List of ids to assign to documents.\n",
            " |              If not specified, UUIDs will be generated. Defaults to None.\n",
            " |          batch_size (int, optional):\n",
            " |              How many documents to embed and upload in single request. Defaults to 32.\n",
            " |          parallel (Optional[int], optional):\n",
            " |              How many parallel workers to use for embedding. Defaults to None.\n",
            " |              If number is specified, data-parallel process will be used.\n",
            " |      \n",
            " |      Raises:\n",
            " |          ImportError: If fastembed is not installed.\n",
            " |      \n",
            " |      Returns:\n",
            " |          List of IDs of added documents. If no ids provided, UUIDs will be randomly generated on client side.\n",
            " |  \n",
            " |  get_fastembed_sparse_vector_params(self, on_disk: Optional[bool] = None) -> Optional[Dict[str, qdrant_client.http.models.models.SparseVectorParams]]\n",
            " |      Generates vector configuration, compatible with fastembed sparse models.\n",
            " |      \n",
            " |      Args:\n",
            " |          on_disk: if True, vectors will be stored on disk. If None, default value will be used.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Configuration for `vectors_config` argument in `create_collection` method.\n",
            " |  \n",
            " |  get_fastembed_vector_params(self, on_disk: Optional[bool] = None, quantization_config: Union[qdrant_client.http.models.models.ScalarQuantization, qdrant_client.http.models.models.ProductQuantization, qdrant_client.http.models.models.BinaryQuantization, NoneType] = None, hnsw_config: Optional[qdrant_client.http.models.models.HnswConfigDiff] = None) -> Dict[str, qdrant_client.http.models.models.VectorParams]\n",
            " |      Generates vector configuration, compatible with fastembed models.\n",
            " |      \n",
            " |      Args:\n",
            " |          on_disk: if True, vectors will be stored on disk. If None, default value will be used.\n",
            " |          quantization_config: Quantization configuration. If None, quantization will be disabled.\n",
            " |          hnsw_config: HNSW configuration. If None, default configuration will be used.\n",
            " |      \n",
            " |      Returns:\n",
            " |          Configuration for `vectors_config` argument in `create_collection` method.\n",
            " |  \n",
            " |  get_sparse_vector_field_name(self) -> Optional[str]\n",
            " |      Returns name of the vector field in qdrant collection, used by current fastembed model.\n",
            " |      Returns:\n",
            " |          Name of the vector field.\n",
            " |  \n",
            " |  get_vector_field_name(self) -> str\n",
            " |      Returns name of the vector field in qdrant collection, used by current fastembed model.\n",
            " |      Returns:\n",
            " |          Name of the vector field.\n",
            " |  \n",
            " |  query(self, collection_name: str, query_text: str, query_filter: Optional[qdrant_client.http.models.models.Filter] = None, limit: int = 10, **kwargs: Any) -> List[qdrant_client.fastembed_common.QueryResponse]\n",
            " |      Search for documents in a collection.\n",
            " |      This method automatically embeds the query text using the specified embedding model.\n",
            " |      If you want to use your own query vector, use `search` method instead.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Collection to search in\n",
            " |          query_text:\n",
            " |              Text to search for. This text will be embedded using the specified embedding model.\n",
            " |              And then used as a query vector.\n",
            " |          query_filter:\n",
            " |              - Exclude vectors which doesn't fit given conditions.\n",
            " |              - If `None` - search among all vectors\n",
            " |          limit: How many results return\n",
            " |          **kwargs: Additional search parameters. See `qdrant_client.models.SearchRequest` for details.\n",
            " |      \n",
            " |      Returns:\n",
            " |          List[types.ScoredPoint]: List of scored points.\n",
            " |  \n",
            " |  query_batch(self, collection_name: str, query_texts: List[str], query_filter: Optional[qdrant_client.http.models.models.Filter] = None, limit: int = 10, **kwargs: Any) -> List[List[qdrant_client.fastembed_common.QueryResponse]]\n",
            " |      Search for documents in a collection with batched query.\n",
            " |      This method automatically embeds the query text using the specified embedding model.\n",
            " |      \n",
            " |      Args:\n",
            " |          collection_name: Collection to search in\n",
            " |          query_texts:\n",
            " |              A list of texts to search for. Each text will be embedded using the specified embedding model.\n",
            " |              And then used as a query vector for a separate search requests.\n",
            " |          query_filter:\n",
            " |              - Exclude vectors which doesn't fit given conditions.\n",
            " |              - If `None` - search among all vectors\n",
            " |              This filter will be applied to all search requests.\n",
            " |          limit: How many results return\n",
            " |          **kwargs: Additional search parameters. See `qdrant_client.models.SearchRequest` for details.\n",
            " |      \n",
            " |      Returns:\n",
            " |          List[List[QueryResponse]]: List of lists of responses for each query text.\n",
            " |  \n",
            " |  set_model(self, embedding_model_name: str, max_length: Optional[int] = None, cache_dir: Optional[str] = None, threads: Optional[int] = None, **kwargs: Any) -> None\n",
            " |      Set embedding model to use for encoding documents and queries.\n",
            " |      Args:\n",
            " |          embedding_model_name: One of the supported embedding models. See `SUPPORTED_EMBEDDING_MODELS` for details.\n",
            " |          max_length (int, optional): Deprecated. Defaults to None.\n",
            " |          cache_dir (str, optional): The path to the cache directory.\n",
            " |                                     Can be set using the `FASTEMBED_CACHE_PATH` env variable.\n",
            " |                                     Defaults to `fastembed_cache` in the system's temp directory.\n",
            " |          threads (int, optional): The number of threads single onnxruntime session can use. Defaults to None.\n",
            " |      Raises:\n",
            " |          ValueError: If embedding model is not supported.\n",
            " |          ImportError: If fastembed is not installed.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None\n",
            " |  \n",
            " |  set_sparse_model(self, embedding_model_name: Optional[str], cache_dir: Optional[str] = None, threads: Optional[int] = None) -> None\n",
            " |      Set sparse embedding model to use for hybrid search over documents in combination with dense embeddings.\n",
            " |      Args:\n",
            " |          embedding_model_name: One of the supported sparse embedding models. See `SUPPORTED_SPARSE_EMBEDDING_MODELS` for details.\n",
            " |                      If None, sparse embeddings will not be used.\n",
            " |          cache_dir (str, optional): The path to the cache directory.\n",
            " |                                     Can be set using the `FASTEMBED_CACHE_PATH` env variable.\n",
            " |                                     Defaults to `fastembed_cache` in the system's temp directory.\n",
            " |          threads (int, optional): The number of threads single onnxruntime session can use. Defaults to None.\n",
            " |      Raises:\n",
            " |          ValueError: If embedding model is not supported.\n",
            " |          ImportError: If fastembed is not installed.\n",
            " |      \n",
            " |      Returns:\n",
            " |          None\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Readonly properties inherited from qdrant_client.qdrant_fastembed.QdrantFastembedMixin:\n",
            " |  \n",
            " |  embedding_model_name\n",
            " |  \n",
            " |  sparse_embedding_model_name\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data and other attributes inherited from qdrant_client.qdrant_fastembed.QdrantFastembedMixin:\n",
            " |  \n",
            " |  DEFAULT_EMBEDDING_MODEL = 'BAAI/bge-small-en'\n",
            " |  \n",
            " |  embedding_models = {}\n",
            " |  \n",
            " |  sparse_embedding_models = {}\n",
            " |  \n",
            " |  ----------------------------------------------------------------------\n",
            " |  Data descriptors inherited from qdrant_client.client_base.QdrantBase:\n",
            " |  \n",
            " |  __dict__\n",
            " |      dictionary for instance variables\n",
            " |  \n",
            " |  __weakref__\n",
            " |      list of weak references to the object\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from qdrant_client import QdrantClient\n",
        "client = QdrantClient(path=\"persist_dir\") \n",
        "help(client)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCC2AR-Q0m0x",
        "outputId": "fe623cdf-cc3d-4ddd-fc8e-9405c5be8c50"
      },
      "outputs": [],
      "source": [
        "!pip install -qU langchain langchain-core langchain-community langchain-openai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5ELHQjQ1PYs"
      },
      "source": [
        "Now we can get our Qdrant dependencies!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "76XeYI9P1OXO",
        "outputId": "6384050b-85e9-44b5-bc91-18608fe62cd0"
      },
      "outputs": [],
      "source": [
        "!pip install -qU qdrant-client"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iesey9OGCKJx"
      },
      "source": [
        "Let's finally get `tiktoken` and `pymupdf` so we can leverage them later on!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K5qIUrFuENrS",
        "outputId": "1e6e0c65-b0e6-4997-8dc0-8e1528c27b8f"
      },
      "outputs": [],
      "source": [
        "!pip install -qU tiktoken pymupdf"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl6wTp9C5qbY"
      },
      "source": [
        "#### Set Environment \n",
        "\n",
        "We will read from .env\n",
        "and use config to control the constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = 'studybuddy_utils/'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "load_dotenv()\n",
        "\n",
        "# tbd make sure, the key has been loaded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from studybuddy_utils.config import Config"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Set up LangSmith"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "from uuid import uuid4\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"StudyBuddy - Development - {uuid4().hex[0:8]}\"\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n4AozVoEZveK"
      },
      "source": [
        "#### Read and chunk docs"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kocCe4zLy5qT"
      },
      "source": [
        "### Create embeddings and setup vector store"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Experiment the fine-tuned model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install sentence_transformers\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The token has not been saved to the git credentials helper. Pass `add_to_git_credential=True` in this function directly or `--add-to-git-credential` if using via `huggingface-cli` if you want to set the git credential as well.\n",
            "Token is valid (permission: write).\n",
            "Your token has been saved to /Users/ursuladeriu/.cache/huggingface/token\n",
            "Login successful\n"
          ]
        }
      ],
      "source": [
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "\n",
        "from huggingface_hub import login\n",
        "\n",
        "login(token=os.getenv('HF_TOKEN'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/opt/homebrew/Caskroom/miniforge/base/envs/llmops-course/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e23a44f643eb4817907310b32e79034f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.46k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a2b9c0cc2e3f46dbab4e0196af44244f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.model:   0%|          | 0.00/493k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b5fac682671b445a92caa1227fe8b729",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.80M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1ee6ebdc2b8f403aa8ca613fbd362ee7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/438 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_id = \"uderiu/mistral7binstruct_summarize\"\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
        "\n",
        "from langchain_community.embeddings import HuggingFaceHubEmbeddings\n",
        "model = \"uderiu/mistral7binstruct_summarize\"\n",
        "hf = HuggingFaceHubEmbeddings(\n",
        "    model=model,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "LlamaTokenizerFast(name_or_path='uderiu/mistral7binstruct_summarize', vocab_size=32000, model_max_length=1000000000000000019884624838656, is_fast=True, padding_side='left', truncation_side='right', special_tokens={'bos_token': '<s>', 'eos_token': '</s>', 'unk_token': '<unk>', 'pad_token': '<unk>'}, clean_up_tokenization_spaces=False),  added_tokens_decoder={\n",
              "\t0: AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t1: AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "\t2: AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=False, special=True),\n",
              "}"
            ]
          },
          "execution_count": 23,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install peft bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "from peft import AutoPeftModelForCausalLM\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_use_double_quant=True,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        ")\n",
        "\n",
        "model = AutoPeftModelForCausalLM.from_pretrained(\n",
        "    model_id,\n",
        "    device_map=\"auto\",\n",
        "    torch_dtype=torch.float16,\n",
        "    quantization_config=quantization_config,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "path = './data/sudel.pdf'\n",
        "from langchain.document_loaders import PyMuPDFLoader\n",
        "docs = PyMuPDFLoader(path).load()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "def token_len(text):\n",
        "  tokens = tokenizer.encoding_for_model(model_id).encode(\n",
        "            text,\n",
        "        )\n",
        "  return len(tokens) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "text_splitter = RecursiveCharacterTextSplitter(\n",
        "            chunk_size = 200,\n",
        "            chunk_overlap = 30,\n",
        "            length_function = token_len, \n",
        "        )\n",
        "split_chunks = text_splitter.split_documents(docs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "HuggingFaceHubEmbeddings(client=<InferenceClient(model='uderiu/e2erag-ir-arctic-m', timeout=None)>, async_client=<InferenceClient(model='uderiu/e2erag-ir-arctic-m', timeout=None)>, model='uderiu/e2erag-ir-arctic-m', repo_id='uderiu/e2erag-ir-arctic-m', task='feature-extraction', model_kwargs=None, huggingfacehub_api_token=None)"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "vector_store = FAISS.from_documents(split_chunks, hf)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install langchain openai tiktoken transformers accelerate cohere --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "uderiu/mistral7binstruct_summarize\n"
          ]
        }
      ],
      "source": [
        "from langchain import HuggingFaceHub\n",
        "from getpass import getpass\n",
        " \n",
        "\n",
        " \n",
        "repo_id = \"uderiu/mistral7binstruct_summarize\"\n",
        "print(repo_id)\n",
        " \n",
        "llm = HuggingFaceHub(repo_id=repo_id, task='conversational', model_kwargs={\"temperature\":0, \"max_length\":64})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {},
      "outputs": [],
      "source": [
        "from langchain import PromptTemplate, LLMChain\n",
        " \n",
        "template = \"\"\"Question: {question}\n",
        " \n",
        "Answer: Let's think step by step.\"\"\"\n",
        "prompt = PromptTemplate(template=template, input_variables=[\"question\"])\n",
        "llm_chain = LLMChain(prompt=prompt, llm=llm)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = 'In the first movie of Harry Potter, what is the name of the three-headed dog?'\n",
        "print(question)\n",
        "print(llm_chain.invoke(question))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {},
      "outputs": [],
      "source": [
        "from huggingface_hub import login\n",
        "token='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'\n",
        "login(token=token)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 64,
      "metadata": {},
      "outputs": [
        {
          "ename": "BadRequestError",
          "evalue": " (Request ID: PQIIDivZNUbIJTfRF6dgs)\n\nBad request:\nAuthorization header is correct, but the token seems invalid",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPError\u001b[0m                                 Traceback (most recent call last)",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llmops-course/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:304\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 304\u001b[0m     \u001b[43mresponse\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mraise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llmops-course/lib/python3.11/site-packages/requests/models.py:1021\u001b[0m, in \u001b[0;36mResponse.raise_for_status\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1020\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m http_error_msg:\n\u001b[0;32m-> 1021\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m HTTPError(http_error_msg, response\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m)\n",
            "\u001b[0;31mHTTPError\u001b[0m: 400 Client Error: Bad Request for url: https://api-inference.huggingface.co/models/uderiu/mistral7binstruct_summarize",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mBadRequestError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[64], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m chain \u001b[38;5;241m=\u001b[39m prompt \u001b[38;5;241m|\u001b[39m llm\n\u001b[0;32m----> 3\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mchain\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mquestion\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m response\u001b[38;5;241m.\u001b[39mcontent\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llmops-course/lib/python3.11/site-packages/langchain_core/runnables/base.py:2499\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config)\u001b[0m\n\u001b[1;32m   2497\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   2498\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m i, step \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps):\n\u001b[0;32m-> 2499\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2500\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2501\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;66;43;03m# mark each step as a child run\u001b[39;49;00m\n\u001b[1;32m   2502\u001b[0m \u001b[43m            \u001b[49m\u001b[43mpatch_config\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   2503\u001b[0m \u001b[43m                \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_child\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mseq:step:\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2504\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   2505\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2506\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   2507\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llmops-course/lib/python3.11/site-packages/langchain_core/language_models/llms.py:276\u001b[0m, in \u001b[0;36mBaseLLM.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    266\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    268\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    273\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m    274\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (\n\u001b[0;32m--> 276\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    280\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    281\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    282\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    283\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    284\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    285\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    286\u001b[0m         \u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    287\u001b[0m         \u001b[38;5;241m.\u001b[39mtext\n\u001b[1;32m    288\u001b[0m     )\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llmops-course/lib/python3.11/site-packages/langchain_core/language_models/llms.py:633\u001b[0m, in \u001b[0;36mBaseLLM.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    625\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    626\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    627\u001b[0m     prompts: List[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    631\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    632\u001b[0m     prompt_strings \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_string() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 633\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_strings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llmops-course/lib/python3.11/site-packages/langchain_core/language_models/llms.py:803\u001b[0m, in \u001b[0;36mBaseLLM.generate\u001b[0;34m(self, prompts, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    788\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m get_llm_cache() \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    789\u001b[0m     run_managers \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    790\u001b[0m         callback_manager\u001b[38;5;241m.\u001b[39mon_llm_start(\n\u001b[1;32m    791\u001b[0m             dumpd(\u001b[38;5;28mself\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    801\u001b[0m         )\n\u001b[1;32m    802\u001b[0m     ]\n\u001b[0;32m--> 803\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_helper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[43m        \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mbool\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_arg_supported\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    805\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    806\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n\u001b[1;32m    807\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(missing_prompts) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llmops-course/lib/python3.11/site-packages/langchain_core/language_models/llms.py:670\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    668\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n\u001b[1;32m    669\u001b[0m         run_manager\u001b[38;5;241m.\u001b[39mon_llm_error(e, response\u001b[38;5;241m=\u001b[39mLLMResult(generations\u001b[38;5;241m=\u001b[39m[]))\n\u001b[0;32m--> 670\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\n\u001b[1;32m    671\u001b[0m flattened_outputs \u001b[38;5;241m=\u001b[39m output\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m manager, flattened_output \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mzip\u001b[39m(run_managers, flattened_outputs):\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llmops-course/lib/python3.11/site-packages/langchain_core/language_models/llms.py:657\u001b[0m, in \u001b[0;36mBaseLLM._generate_helper\u001b[0;34m(self, prompts, stop, run_managers, new_arg_supported, **kwargs)\u001b[0m\n\u001b[1;32m    647\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_generate_helper\u001b[39m(\n\u001b[1;32m    648\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    649\u001b[0m     prompts: List[\u001b[38;5;28mstr\u001b[39m],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    653\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    654\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    655\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    656\u001b[0m         output \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m--> 657\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    658\u001b[0m \u001b[43m                \u001b[49m\u001b[43mprompts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;66;43;03m# TODO: support multiple run managers\u001b[39;49;00m\n\u001b[1;32m    661\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    662\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    663\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    664\u001b[0m             \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m    665\u001b[0m             \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(prompts, stop\u001b[38;5;241m=\u001b[39mstop)\n\u001b[1;32m    666\u001b[0m         )\n\u001b[1;32m    667\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    668\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m run_manager \u001b[38;5;129;01min\u001b[39;00m run_managers:\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llmops-course/lib/python3.11/site-packages/langchain_core/language_models/llms.py:1317\u001b[0m, in \u001b[0;36mLLM._generate\u001b[0;34m(self, prompts, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m   1314\u001b[0m new_arg_supported \u001b[38;5;241m=\u001b[39m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1315\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m prompt \u001b[38;5;129;01min\u001b[39;00m prompts:\n\u001b[1;32m   1316\u001b[0m     text \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m-> 1317\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1318\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m new_arg_supported\n\u001b[1;32m   1319\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(prompt, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1320\u001b[0m     )\n\u001b[1;32m   1321\u001b[0m     generations\u001b[38;5;241m.\u001b[39mappend([Generation(text\u001b[38;5;241m=\u001b[39mtext)])\n\u001b[1;32m   1322\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m LLMResult(generations\u001b[38;5;241m=\u001b[39mgenerations)\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llmops-course/lib/python3.11/site-packages/langchain_community/llms/huggingface_hub.py:135\u001b[0m, in \u001b[0;36mHuggingFaceHub._call\u001b[0;34m(self, prompt, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    132\u001b[0m _model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel_kwargs \u001b[38;5;129;01mor\u001b[39;00m {}\n\u001b[1;32m    133\u001b[0m parameters \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m_model_kwargs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 135\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpost\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minputs\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mparameters\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mparameters\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtask\u001b[49m\n\u001b[1;32m    137\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m response \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mloads(response\u001b[38;5;241m.\u001b[39mdecode())\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124merror\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m response:\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llmops-course/lib/python3.11/site-packages/huggingface_hub/inference/_client.py:273\u001b[0m, in \u001b[0;36mInferenceClient.post\u001b[0;34m(self, json, data, model, task, stream)\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InferenceTimeoutError(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInference call timed out: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merror\u001b[39;00m  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    272\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 273\u001b[0m     \u001b[43mhf_raise_for_status\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    274\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39miter_lines() \u001b[38;5;28;01mif\u001b[39;00m stream \u001b[38;5;28;01melse\u001b[39;00m response\u001b[38;5;241m.\u001b[39mcontent\n\u001b[1;32m    275\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HTTPError \u001b[38;5;28;01mas\u001b[39;00m error:\n",
            "File \u001b[0;32m/opt/homebrew/Caskroom/miniforge/base/envs/llmops-course/lib/python3.11/site-packages/huggingface_hub/utils/_errors.py:358\u001b[0m, in \u001b[0;36mhf_raise_for_status\u001b[0;34m(response, endpoint_name)\u001b[0m\n\u001b[1;32m    354\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m400\u001b[39m:\n\u001b[1;32m    355\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    356\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mendpoint_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m endpoint:\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m endpoint_name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mBad request:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    357\u001b[0m     )\n\u001b[0;32m--> 358\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadRequestError(message, response\u001b[38;5;241m=\u001b[39mresponse) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    360\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m response\u001b[38;5;241m.\u001b[39mstatus_code \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m403\u001b[39m:\n\u001b[1;32m    361\u001b[0m     message \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    362\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Forbidden: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    363\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mCannot access content at: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    364\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mIf you are trying to create or update content,\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmake sure you have a token with the `write` role.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    366\u001b[0m     )\n",
            "\u001b[0;31mBadRequestError\u001b[0m:  (Request ID: PQIIDivZNUbIJTfRF6dgs)\n\nBad request:\nAuthorization header is correct, but the token seems invalid"
          ]
        }
      ],
      "source": [
        "chain = prompt | llm\n",
        "        \n",
        "response = chain.invoke({\"question\": question})\n",
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Evaluator\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [],
      "source": [
        "# from studybuddy_utils.prompts import EvaluationPrompt\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "load_dotenv()\n",
        "\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "openai_chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "system_prompt = \"\"\"\n",
        "You are a university professor grading a quiz in information retrieval.\n",
        "\n",
        "You should be hyper-critical.\n",
        "\n",
        "Provide scores (out of 10) for the following attributes:\n",
        "\n",
        "1. Clarity - how clear is the response\n",
        "2. Faithfulness - how related to the original query is the response\n",
        "3. Correctness - was the response correct?\n",
        "\n",
        "\n",
        "The question is given below:\n",
        "\n",
        "---------------------\n",
        "{question}\n",
        "---------------------\n",
        "\n",
        "Given the question score the user's answer based on the ideal answer provided here:\n",
        "\n",
        "---------------------\n",
        "{ideal_answer}\n",
        "---------------------\n",
        "Please take your time, and think through each item step-by-step.\n",
        "If you don't know then simply provide scores -1.\n",
        "When you are done -  please provide your response in a JSON format as follows:\n",
        "\n",
        "\"clarity\" : \"score_out_of_10\", \"faithfulness\" : \"score_out_of_10\", \"correctness\" : \"score_out_of_10\"\n",
        "\"\"\"\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [],
      "source": [
        "human_prompt = \"\"\"\n",
        "Based on the information given, score the following answer:\n",
        "---------------------\n",
        "{student_answer}\n",
        "---------------------\n",
        "\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Based on the information given, score the following answer:\n",
            "---------------------\n",
            "juhu\n",
            "---------------------\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "aa=system_prompt.format(question='gugus', ideal_answer='dada')\n",
        "# print(aa)\n",
        "bb=human_prompt.format(student_answer='juhu')\n",
        "#print(bb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [],
      "source": [
        "question = \"Define the term: precision\"\n",
        "ideal_answer = \"Precision is the fraction of relevant instances among the retrieved instances.\"\n",
        "answer = \"It is simply not the same as recall\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['ideal_answer', 'question', 'student_answer'], messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['ideal_answer', 'question'], template='\\nYou are a university professor grading a quiz in information retrieval.\\n\\nYou should be hyper-critical.\\n\\nProvide scores (out of 10) for the following attributes:\\n\\n1. Clarity - how clear is the response\\n2. Faithfulness - how related to the original query is the response\\n3. Correctness - was the response correct?\\n\\n\\nThe question is given below:\\n\\n---------------------\\n{question}\\n---------------------\\n\\nGiven the question score the user\\'s answer based on the ideal answer provided here:\\n\\n---------------------\\n{ideal_answer}\\n---------------------\\nPlease take your time, and think through each item step-by-step.\\nIf you don\\'t know then simply provide scores -1.\\nWhen you are done -  please provide your response in a JSON format as follows:\\n\\n\"clarity\" : \"score_out_of_10\", \"faithfulness\" : \"score_out_of_10\", \"correctness\" : \"score_out_of_10\"\\n')), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['student_answer'], template='\\nBased on the information given, score the following answer:\\n---------------------\\n{student_answer}\\n---------------------\\n\\n'))])"
            ]
          },
          "execution_count": 37,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", system_prompt),\n",
        "    (\"human\", human_prompt)\n",
        "])\n",
        "chat_prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "chain = chat_prompt | openai_chat_model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [],
      "source": [
        "response = chain.invoke({\"question\": question, \n",
        "                        \"ideal_answer\": ideal_answer,\n",
        "                        \"student_answer\": answer})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'\"clarity\" : \"2\", \"faithfulness\" : \"1\", \"correctness\" : \"0\"'"
            ]
          },
          "execution_count": 41,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "response.content"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Finetuned Embeddings Seem to Work"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {},
      "outputs": [],
      "source": [
        "pip install langchain sentence-transformers"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 107,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92a3dce4d2af409297aff64f83da7acf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2d465b96791c430fafb05c9bf6750530",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config_sentence_transformers.json:   0%|          | 0.00/252 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You try to use a model that was created with version 2.7.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
            "\n",
            "\n",
            "\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4454c6043dcf402cb1e69702c1a5d5b4",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "README.md:   0%|          | 0.00/2.61k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7a53a8e0423e4e76baa3fcc22a9f01a1",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "fed9990825094be3bd78fb5fdac06f0b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "config.json:   0%|          | 0.00/662 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ef26b313228141619c8f60e12fa01f55",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f2eb142d14724ee0af5f6f843efa76c5",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/1.38k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dd9de11b0b82482e9f9e31c55b665627",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5d17dd6835f14d96b31005f74593184f",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/712k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "ce7b9f17d40646a4b946ff3ed12de9bf",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "special_tokens_map.json:   0%|          | 0.00/695 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8ee384e8bc1e426db8b7375d489e9e12",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "1_Pooling/config.json:   0%|          | 0.00/296 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "\n",
        "model = SentenceTransformer('uderiu/snowflake-ft-ir2-m')  # This will download the model if needed"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 113,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "You try to use a model that was created with version 2.7.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
            "\n",
            "\n",
            "\n",
            "/opt/homebrew/Caskroom/miniforge/base/envs/llmops-course/lib/python3.11/site-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n",
            "You try to use a model that was created with version 2.7.0.dev0, however, your version is 2.7.0. This might cause unexpected behavior or errors. In that case, try to update to the latest version.\n",
            "\n",
            "\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from sentence_transformers import SentenceTransformer\n",
        "# model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
        "model_name = \"uderiu/snowflake-ft-ir2-m\"\n",
        "embeddings = HuggingFaceEmbeddings(model_name=model_name)\n",
        "embeddings = SentenceTransformer(\"uderiu/snowflake-ft-ir2-m\")\n",
        "\n",
        "help(embeddings)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "text = \"This is a sentence to embed.\"\n",
        "query_result = embeddings.embed_query(text)\n",
        "\n",
        "texts = [\"This is a sentence to embed.\", \"This is another one.\"]\n",
        "doc_result = embeddings.embed_documents(texts)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 106,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "[-0.03943974897265434,\n",
              " 0.020284269005060196,\n",
              " 0.005326754413545132,\n",
              " 0.01672498881816864,\n",
              " 0.04289831593632698,\n",
              " 0.03348741680383682,\n",
              " 0.02052289806306362,\n",
              " -0.010166269727051258,\n",
              " -0.05151605233550072,\n",
              " -0.003706497373059392,\n",
              " -0.07337256520986557,\n",
              " -0.019492991268634796,\n",
              " -0.02111571468412876,\n",
              " -0.010406372137367725,\n",
              " 0.0039052683860063553,\n",
              " -0.03507259860634804,\n",
              " -6.35115648037754e-05,\n",
              " -0.02606702595949173,\n",
              " 0.024259300902485847,\n",
              " -0.040775299072265625,\n",
              " -0.025847500190138817,\n",
              " 0.02115398645401001,\n",
              " 0.00375823094509542,\n",
              " -0.001967289485037327,\n",
              " -0.019367370754480362,\n",
              " 0.04025669023394585,\n",
              " 0.035032227635383606,\n",
              " -0.025257043540477753,\n",
              " -0.10125736892223358,\n",
              " -0.04604853689670563,\n",
              " 0.015001820400357246,\n",
              " 0.005576154682785273,\n",
              " -0.0013439432950690389,\n",
              " -0.07189872115850449,\n",
              " -0.011926593258976936,\n",
              " -0.0803970918059349,\n",
              " -0.021916529163718224,\n",
              " 0.01933901198208332,\n",
              " -0.02328803576529026,\n",
              " -0.021346440538764,\n",
              " -0.028564810752868652,\n",
              " 0.00686455424875021,\n",
              " 0.031726859509944916,\n",
              " 0.021980207413434982,\n",
              " -0.05872315913438797,\n",
              " -0.00019155973859596997,\n",
              " -0.08817137777805328,\n",
              " 0.011609180830419064,\n",
              " -0.0007124709663912654,\n",
              " -0.026708751916885376,\n",
              " -0.0019452814012765884,\n",
              " 0.08179610967636108,\n",
              " 0.013618065044283867,\n",
              " 0.021413875743746758,\n",
              " 0.000768365222029388,\n",
              " 0.023242270573973656,\n",
              " 0.04476591944694519,\n",
              " -0.05891893804073334,\n",
              " -0.00987948477268219,\n",
              " -0.08062300831079483,\n",
              " 0.09302856773138046,\n",
              " -0.011016438715159893,\n",
              " 0.04321952909231186,\n",
              " 0.054160792380571365,\n",
              " -0.018444513902068138,\n",
              " -0.05544931814074516,\n",
              " -0.04383179172873497,\n",
              " -0.03326934203505516,\n",
              " -0.023758184164762497,\n",
              " -0.028791215270757675,\n",
              " -0.03376682847738266,\n",
              " 0.013690882362425327,\n",
              " -0.0024208540562540293,\n",
              " 0.010914655402302742,\n",
              " 0.0483454205095768,\n",
              " -0.04473073035478592,\n",
              " 0.046624805778265,\n",
              " 0.015467704273760319,\n",
              " 0.02304415963590145,\n",
              " 0.0636623352766037,\n",
              " -0.04645146057009697,\n",
              " -0.03133068606257439,\n",
              " 0.056072838604450226,\n",
              " 0.037073373794555664,\n",
              " -0.016306938603520393,\n",
              " -0.002126404084265232,\n",
              " 0.009655279107391834,\n",
              " 0.028470173478126526,\n",
              " -0.0038481527008116245,\n",
              " 0.05502773076295853,\n",
              " -0.010025360621511936,\n",
              " -0.02180221490561962,\n",
              " -0.0018269446445629,\n",
              " 0.01678488962352276,\n",
              " 0.03545254468917847,\n",
              " 0.022178029641509056,\n",
              " 0.006436552386730909,\n",
              " -0.0027976571582257748,\n",
              " 0.0015488213393837214,\n",
              " 0.00770446565002203,\n",
              " -0.03067396953701973,\n",
              " -0.02338751219213009,\n",
              " -0.01136105041950941,\n",
              " -0.016872845590114594,\n",
              " -0.06111101433634758,\n",
              " -0.004368175752460957,\n",
              " 0.03765867277979851,\n",
              " -0.00871011521667242,\n",
              " -2.938148463726975e-05,\n",
              " 0.0009232588927261531,\n",
              " -0.004361545201390982,\n",
              " -0.027664490044116974,\n",
              " -0.009372842498123646,\n",
              " -0.033401671797037125,\n",
              " -0.015707116574048996,\n",
              " 0.04061416909098625,\n",
              " 0.01033276692032814,\n",
              " 0.012601819820702076,\n",
              " 0.0022528916597366333,\n",
              " -0.010134049691259861,\n",
              " 0.01894216425716877,\n",
              " 0.0814456045627594,\n",
              " 0.0652393028140068,\n",
              " 0.03470209985971451,\n",
              " 0.010681028477847576,\n",
              " 0.005928493570536375,\n",
              " 0.01249164342880249,\n",
              " 0.030181339010596275,\n",
              " -0.030345819890499115,\n",
              " -0.01536629069596529,\n",
              " 0.03937356173992157,\n",
              " 0.07972244173288345,\n",
              " 0.031368330121040344,\n",
              " -0.015351041220128536,\n",
              " 0.05320321023464203,\n",
              " -0.021246418356895447,\n",
              " -0.044278837740421295,\n",
              " -0.05387014523148537,\n",
              " 0.03371378034353256,\n",
              " -0.032533224672079086,\n",
              " -0.006750942207872868,\n",
              " 0.055725689977407455,\n",
              " 0.0034981435164809227,\n",
              " -0.07983822375535965,\n",
              " 0.030116984620690346,\n",
              " 0.005380183923989534,\n",
              " -0.0443420447409153,\n",
              " 0.056347526609897614,\n",
              " 0.008557502180337906,\n",
              " 0.037524957209825516,\n",
              " 0.04680239036679268,\n",
              " 0.03542397916316986,\n",
              " -0.005232406780123711,\n",
              " -0.024586642161011696,\n",
              " 0.004817594308406115,\n",
              " 0.03786548599600792,\n",
              " 0.005178773310035467,\n",
              " -0.015762414783239365,\n",
              " -0.021847311407327652,\n",
              " 0.003243819111958146,\n",
              " 0.008983793668448925,\n",
              " -0.026384536176919937,\n",
              " 0.021877314895391464,\n",
              " 0.05775237828493118,\n",
              " -0.048639848828315735,\n",
              " 0.010579671710729599,\n",
              " -0.03076319582760334,\n",
              " 0.02141145057976246,\n",
              " -0.02093394845724106,\n",
              " -0.004425819963216782,\n",
              " -0.05651182308793068,\n",
              " -0.05070555955171585,\n",
              " 0.05587807670235634,\n",
              " -0.01895114779472351,\n",
              " 0.021026529371738434,\n",
              " 0.00030236359452828765,\n",
              " 0.04692211374640465,\n",
              " 0.03840018808841705,\n",
              " 0.02763265185058117,\n",
              " -0.01206912100315094,\n",
              " -0.01304746326059103,\n",
              " 0.040758922696113586,\n",
              " 0.0008313708240166306,\n",
              " 0.030748553574085236,\n",
              " -0.043101076036691666,\n",
              " 0.023149147629737854,\n",
              " -0.005237814038991928,\n",
              " -0.06348689645528793,\n",
              " -0.06304274499416351,\n",
              " 0.01608136296272278,\n",
              " -0.04710385948419571,\n",
              " -0.051204413175582886,\n",
              " -0.046387746930122375,\n",
              " 0.009226217865943909,\n",
              " 0.028859196230769157,\n",
              " 0.044283196330070496,\n",
              " -0.026374638080596924,\n",
              " -0.04083659499883652,\n",
              " -0.035649389028549194,\n",
              " 0.06574402749538422,\n",
              " 0.017105253413319588,\n",
              " 0.040713366121053696,\n",
              " 0.02209566906094551,\n",
              " -0.06083531677722931,\n",
              " -0.01543543953448534,\n",
              " 0.00402022385969758,\n",
              " -0.024646230041980743,\n",
              " -0.016509227454662323,\n",
              " 0.035408638417720795,\n",
              " 0.09534362703561783,\n",
              " 0.017143186181783676,\n",
              " 0.016919618472456932,\n",
              " 0.05229489505290985,\n",
              " -0.0017415458569303155,\n",
              " -0.006524155382066965,\n",
              " -0.0074203237891197205,\n",
              " 0.0009749214514158666,\n",
              " -0.04561571776866913,\n",
              " -0.017784010618925095,\n",
              " 0.011079312302172184,\n",
              " 0.017672093585133553,\n",
              " -0.07006619870662689,\n",
              " 0.0014249293599277735,\n",
              " 0.011365235783159733,\n",
              " -0.025321662425994873,\n",
              " 0.027486374601721764,\n",
              " -0.00525523629039526,\n",
              " -0.01841917261481285,\n",
              " -0.0043535009026527405,\n",
              " 0.00868029985576868,\n",
              " 0.007207586895674467,\n",
              " -0.06869155168533325,\n",
              " 0.03572026640176773,\n",
              " -0.008892443962395191,\n",
              " -0.019593657925724983,\n",
              " 0.0348699726164341,\n",
              " 0.024592259898781776,\n",
              " 0.02090664580464363,\n",
              " 0.008402847684919834,\n",
              " -0.013162230141460896,\n",
              " 0.01512072328478098,\n",
              " 0.05718884617090225,\n",
              " -0.009218845516443253,\n",
              " 0.015183258801698685,\n",
              " -0.016292648389935493,\n",
              " 0.00896426197141409,\n",
              " 0.07289348542690277,\n",
              " -0.033354341983795166,\n",
              " -0.008204677142202854,\n",
              " 0.01807069405913353,\n",
              " -0.04947151616215706,\n",
              " -0.09245279431343079,\n",
              " -0.045826707035303116,\n",
              " -0.03553784266114235,\n",
              " 0.0916559025645256,\n",
              " -0.01706811971962452,\n",
              " -0.010780498385429382,\n",
              " 0.02759127877652645,\n",
              " 0.07132218033075333,\n",
              " 0.02706153877079487,\n",
              " -0.03861773759126663,\n",
              " 0.05024261400103569,\n",
              " -0.016339825466275215,\n",
              " -0.05675074830651283,\n",
              " -0.08718343079090118,\n",
              " 0.01972542330622673,\n",
              " -0.02169070579111576,\n",
              " -0.044705189764499664,\n",
              " 0.01108580082654953,\n",
              " -0.002173112938180566,\n",
              " -0.009288767352700233,\n",
              " -0.006120176520198584,\n",
              " -0.034640222787857056,\n",
              " 0.020220549777150154,\n",
              " 0.0025655757635831833,\n",
              " -0.049166444689035416,\n",
              " 0.02265656366944313,\n",
              " 0.04358064383268356,\n",
              " -0.03395957127213478,\n",
              " 0.031180059537291527,\n",
              " -0.011367694474756718,\n",
              " 0.022107813507318497,\n",
              " 0.001354068168438971,\n",
              " -5.345117824617773e-05,\n",
              " 0.051300495862960815,\n",
              " -0.029833998531103134,\n",
              " -0.012711805291473866,\n",
              " -0.054627083241939545,\n",
              " 0.00861841905862093,\n",
              " -0.012187778949737549,\n",
              " -0.013415430672466755,\n",
              " 0.10360103845596313,\n",
              " -0.0015206648968160152,\n",
              " -0.02292250655591488,\n",
              " 0.006777066737413406,\n",
              " 0.005840812809765339,\n",
              " -0.0029928861185908318,\n",
              " 0.013754894025623798,\n",
              " -0.039328791201114655,\n",
              " 0.019067225977778435,\n",
              " 0.036692481487989426,\n",
              " 0.011547098867595196,\n",
              " 0.007511212024837732,\n",
              " -0.02279984951019287,\n",
              " -0.004986274987459183,\n",
              " -0.030695905908942223,\n",
              " 0.01717381738126278,\n",
              " -0.03481800854206085,\n",
              " 0.010000546462833881,\n",
              " 0.08743219077587128,\n",
              " 0.014402850531041622,\n",
              " -0.0017203280003741384,\n",
              " -0.010102611966431141,\n",
              " 0.04510078579187393,\n",
              " 0.00819992832839489,\n",
              " -0.013827839866280556,\n",
              " -0.015272502787411213,\n",
              " -0.007455633487552404,\n",
              " -0.02203233353793621,\n",
              " 0.019340459257364273,\n",
              " 0.01572749763727188,\n",
              " 0.020055370405316353,\n",
              " 0.022631073370575905,\n",
              " -0.024065308272838593,\n",
              " 0.010452893562614918,\n",
              " -0.019812246784567833,\n",
              " -0.004543065559118986,\n",
              " 0.004897524602711201,\n",
              " 0.02007068321108818,\n",
              " -0.04541132226586342,\n",
              " -0.030391471460461617,\n",
              " 0.01516621932387352,\n",
              " -0.01005051750689745,\n",
              " 0.024818357080221176,\n",
              " 0.012284058146178722,\n",
              " -0.0115755470469594,\n",
              " 0.030062360689044,\n",
              " -0.045863181352615356,\n",
              " -0.0767514780163765,\n",
              " 0.009668397717177868,\n",
              " -0.004074972588568926,\n",
              " -0.04237787425518036,\n",
              " -0.044216640293598175,\n",
              " -0.043539855629205704,\n",
              " -0.000557233695872128,\n",
              " 0.032817479223012924,\n",
              " -0.03308236971497536,\n",
              " -0.0010839492315426469,\n",
              " -0.057932887226343155,\n",
              " 0.05150376260280609,\n",
              " -0.018923843279480934,\n",
              " -0.0202866829931736,\n",
              " -0.005716891959309578,\n",
              " -0.04543522000312805,\n",
              " 0.005277251359075308,\n",
              " -0.059679944068193436,\n",
              " -0.0034841292072087526,\n",
              " 0.06553561240434647,\n",
              " -0.015429770573973656,\n",
              " 0.06894534081220627,\n",
              " 0.02469468303024769,\n",
              " 0.01432111207395792,\n",
              " -0.06078248471021652,\n",
              " 0.00882561132311821,\n",
              " 0.03503655642271042,\n",
              " 0.059031516313552856,\n",
              " -0.04211493954062462,\n",
              " -0.015461738221347332,\n",
              " 0.035918887704610825,\n",
              " -0.02917206659913063,\n",
              " -0.0506356805562973,\n",
              " -0.052567869424819946,\n",
              " 0.04790274053812027,\n",
              " 0.014052585698664188,\n",
              " -0.04406971484422684,\n",
              " -0.04430608078837395,\n",
              " 0.014878006651997566,\n",
              " 0.02692333050072193,\n",
              " -0.018319111317396164,\n",
              " 0.01969851553440094,\n",
              " -0.0010533254826441407,\n",
              " -0.06482681632041931,\n",
              " -0.0022853463888168335,\n",
              " 0.059304844588041306,\n",
              " -0.004771810490638018,\n",
              " -0.01944436877965927,\n",
              " 0.026131613180041313,\n",
              " 0.04224677011370659,\n",
              " -0.06786100566387177,\n",
              " 0.003647629404440522,\n",
              " -0.002355764387175441,\n",
              " 0.075381338596344,\n",
              " -0.025521593168377876,\n",
              " 0.018767226487398148,\n",
              " 0.022826960310339928,\n",
              " -0.023781668394804,\n",
              " -0.0414576455950737,\n",
              " -0.005633888300508261,\n",
              " 0.068433977663517,\n",
              " 0.00921713002026081,\n",
              " 0.03230796009302139,\n",
              " 0.0232658963650465,\n",
              " -0.024529065936803818,\n",
              " 0.025891587138175964,\n",
              " 0.04659023880958557,\n",
              " 0.021756291389465332,\n",
              " 0.0393257662653923,\n",
              " -0.04977933317422867,\n",
              " 0.032581739127635956,\n",
              " -0.09447802603244781,\n",
              " -0.0316520594060421,\n",
              " 0.008742748759686947,\n",
              " 0.03783980756998062,\n",
              " 0.04643739387392998,\n",
              " -0.0966494157910347,\n",
              " 0.011508485302329063,\n",
              " 0.06540953367948532,\n",
              " 0.0050187502056360245,\n",
              " 0.0102704968303442,\n",
              " -0.036551155149936676,\n",
              " -0.013755000196397305,\n",
              " -0.04991523548960686,\n",
              " -0.02677084505558014,\n",
              " -0.03915823623538017,\n",
              " -0.01202122401446104,\n",
              " -0.016679739579558372,\n",
              " 0.005528585519641638,\n",
              " 0.004191334825009108,\n",
              " 0.035254985094070435,\n",
              " -0.0029679739382117987,\n",
              " -0.06457842886447906,\n",
              " -0.021452754735946655,\n",
              " -0.028255615383386612,\n",
              " -0.017984746024012566,\n",
              " 0.01642637699842453,\n",
              " -0.04944179579615593,\n",
              " 0.03337232768535614,\n",
              " -0.014183093793690205,\n",
              " -0.03756273537874222,\n",
              " -0.045589812099933624,\n",
              " -0.017150405794382095,\n",
              " -0.020665008574724197,\n",
              " 0.019135694950819016,\n",
              " -0.004236413165926933,\n",
              " -0.014752385206520557,\n",
              " 0.01937275379896164,\n",
              " 0.025607462972402573,\n",
              " -0.02180892415344715,\n",
              " 0.03492787852883339,\n",
              " -0.007076408248394728,\n",
              " 0.003055020235478878,\n",
              " -0.0232175812125206,\n",
              " 0.0483296737074852,\n",
              " 0.03907744958996773,\n",
              " -0.06254387646913528,\n",
              " 0.05551755800843239,\n",
              " -0.025130782276391983,\n",
              " 0.010114318691194057,\n",
              " 0.01984999142587185,\n",
              " -0.01374618150293827,\n",
              " 0.0256162378937006,\n",
              " -0.015512773767113686,\n",
              " -0.03821397200226784,\n",
              " 0.005021377466619015,\n",
              " 0.04790728539228439,\n",
              " 0.004265123978257179,\n",
              " 0.00900236889719963,\n",
              " 0.04986649751663208,\n",
              " 0.009463358670473099,\n",
              " -0.023238927125930786,\n",
              " -0.0883634015917778,\n",
              " 0.04920043796300888,\n",
              " -0.018742641434073448,\n",
              " 0.056678202003240585,\n",
              " -0.013890212401747704,\n",
              " -0.03262907639145851,\n",
              " 0.03185701742768288,\n",
              " 0.06805644929409027,\n",
              " -0.014586646109819412,\n",
              " -0.0058765411376953125,\n",
              " -0.014467539265751839,\n",
              " 0.04108681157231331,\n",
              " -0.001623400254175067,\n",
              " 0.008063416928052902,\n",
              " -0.05216064676642418,\n",
              " 0.03324584662914276,\n",
              " 0.043028634041547775,\n",
              " 0.026319080963730812,\n",
              " 0.04037642851471901,\n",
              " -0.030206365510821342,\n",
              " -0.022542154416441917,\n",
              " 0.013517101295292377,\n",
              " 0.031926900148391724,\n",
              " -0.010602188296616077,\n",
              " 0.005511478986591101,\n",
              " -0.014580355025827885,\n",
              " -0.06865593045949936,\n",
              " 0.021339576691389084,\n",
              " 0.03753112629055977,\n",
              " -0.012655907310545444,\n",
              " -0.011447090655565262,\n",
              " -0.041548073291778564,\n",
              " 0.023489169776439667,\n",
              " 0.023849699646234512,\n",
              " 0.0035800926852971315,\n",
              " -0.03726058453321457,\n",
              " 0.0008290290716104209,\n",
              " -0.0622856430709362,\n",
              " -0.025957901030778885,\n",
              " -0.0076565369963645935,\n",
              " -0.06820803880691528,\n",
              " 0.06275224685668945,\n",
              " 0.05459000542759895,\n",
              " -0.14367184042930603,\n",
              " 0.021526262164115906,\n",
              " -0.008696611039340496,\n",
              " -0.05960441008210182,\n",
              " 0.00979316420853138,\n",
              " 0.019113318994641304,\n",
              " -0.03818245604634285,\n",
              " -0.056899018585681915,\n",
              " 0.029571987688541412,\n",
              " -0.0271886195987463,\n",
              " -0.031483687460422516,\n",
              " 0.017397385090589523,\n",
              " 0.012616384774446487,\n",
              " 0.007504843175411224,\n",
              " 0.012211887165904045,\n",
              " 0.02743900753557682,\n",
              " -0.05950615182518959,\n",
              " -0.0586097277700901,\n",
              " 0.005979619920253754,\n",
              " -0.00446062907576561,\n",
              " 0.04959515109658241,\n",
              " -0.06990476697683334,\n",
              " 0.023459872230887413,\n",
              " 0.03247533738613129,\n",
              " -0.0020159087143838406,\n",
              " 0.018551474437117577,\n",
              " 0.03353056684136391,\n",
              " -0.004719696007668972,\n",
              " -0.0062227072194218636,\n",
              " -0.00520578445866704,\n",
              " -0.0069861519150435925,\n",
              " 0.009726961143314838,\n",
              " 0.03942131996154785,\n",
              " 0.022390129044651985,\n",
              " 0.0037412582896649837,\n",
              " 0.010111040435731411,\n",
              " 0.06672363728284836,\n",
              " 0.018545908853411674,\n",
              " -0.005940015893429518,\n",
              " -0.027259040623903275,\n",
              " 0.0011026922147721052,\n",
              " 0.005582339130342007,\n",
              " 0.01358984038233757,\n",
              " 0.025466522201895714,\n",
              " 0.02180374786257744,\n",
              " -0.041014671325683594,\n",
              " -0.06801535189151764,\n",
              " -0.01866127736866474,\n",
              " -0.06847713887691498,\n",
              " 0.0021129439119249582,\n",
              " -0.01370090339332819,\n",
              " -0.011113728396594524,\n",
              " -0.007578111719340086,\n",
              " -0.012788107618689537,\n",
              " -0.022350294515490532,\n",
              " 0.019284650683403015,\n",
              " 0.058657798916101456,\n",
              " -0.021729623898863792,\n",
              " 0.04691494628787041,\n",
              " 0.021372413262724876,\n",
              " 0.030017908662557602,\n",
              " -0.0010280435672029853,\n",
              " -0.00628716591745615,\n",
              " 0.032790593802928925,\n",
              " -0.02974817343056202,\n",
              " -0.0007661728886887431,\n",
              " -0.025010814890265465,\n",
              " 0.006983764003962278,\n",
              " 0.009789635427296162,\n",
              " 0.06205988675355911,\n",
              " 0.01706056296825409,\n",
              " -0.030500099062919617,\n",
              " 0.028226474300026894,\n",
              " 0.03637642785906792,\n",
              " -0.03831636533141136,\n",
              " 0.02581961452960968,\n",
              " 0.025655746459960938,\n",
              " -0.052025143057107925,\n",
              " 0.033820170909166336,\n",
              " -0.07384330779314041,\n",
              " -0.020587578415870667,\n",
              " -0.0032395850867033005,\n",
              " 0.03952284902334213,\n",
              " -0.024548066779971123,\n",
              " -0.006560930982232094,\n",
              " -0.022054577246308327,\n",
              " 0.02327153831720352,\n",
              " -0.01787082478404045,\n",
              " -0.025088584050536156,\n",
              " 0.03879692405462265,\n",
              " 0.011286902241408825,\n",
              " 0.02513517625629902,\n",
              " -0.0013832735130563378,\n",
              " -0.042110443115234375,\n",
              " -0.032219260931015015,\n",
              " -0.0008143957238644361,\n",
              " 0.02877267636358738,\n",
              " 0.025953998789191246,\n",
              " -0.01985914446413517,\n",
              " -0.03639931231737137,\n",
              " -0.044288795441389084,\n",
              " -0.012314294464886189,\n",
              " -0.054375968873500824,\n",
              " -0.0167368296533823,\n",
              " 0.07146085053682327,\n",
              " 0.03602492809295654,\n",
              " -0.06709165871143341,\n",
              " 0.02185525931417942,\n",
              " 0.06383402645587921,\n",
              " -0.06883331388235092,\n",
              " -0.07345816493034363,\n",
              " 0.04400809481739998,\n",
              " -0.03635134547948837,\n",
              " -0.06969311088323593,\n",
              " -0.039710190147161484,\n",
              " -0.015020688995718956,\n",
              " -0.09437307715415955,\n",
              " 0.09677925705909729,\n",
              " 0.019397081807255745,\n",
              " 0.020382946357131004,\n",
              " -0.0014230733504518867,\n",
              " -0.03731196001172066,\n",
              " 0.04728977382183075,\n",
              " -0.04083982855081558,\n",
              " 0.02901957556605339,\n",
              " 0.0178692489862442,\n",
              " 0.09656216949224472,\n",
              " 0.030700892210006714,\n",
              " 0.052845362573862076,\n",
              " -0.01557687297463417,\n",
              " 0.0359640046954155,\n",
              " -0.00880616344511509,\n",
              " -0.02845020778477192,\n",
              " 0.0023416040930896997,\n",
              " -0.022684726864099503,\n",
              " 0.0728374496102333,\n",
              " 0.0031066692899912596,\n",
              " -0.009317377582192421,\n",
              " -0.005515252705663443,\n",
              " -0.03631226345896721,\n",
              " 0.010530132800340652,\n",
              " -0.009834294207394123,\n",
              " 0.011283974163234234,\n",
              " -0.029735352843999863,\n",
              " 0.013515773229300976,\n",
              " -0.014566236175596714,\n",
              " 0.008022785186767578,\n",
              " 0.018362464383244514,\n",
              " -0.0180242620408535,\n",
              " 0.08501473069190979,\n",
              " 0.028720902279019356,\n",
              " 0.0008508847095072269,\n",
              " 0.010575552470982075,\n",
              " 0.008700849488377571,\n",
              " 0.030370570719242096,\n",
              " -0.0330975316464901,\n",
              " 0.022657372057437897,\n",
              " 0.08319257944822311,\n",
              " 0.0173263531178236,\n",
              " -0.033055782318115234,\n",
              " 0.014660519547760487,\n",
              " 0.07652439922094345,\n",
              " -0.05710860341787338,\n",
              " 0.0015409125480800867,\n",
              " 0.009209898300468922,\n",
              " 0.015009704045951366,\n",
              " 0.0210883729159832,\n",
              " 0.021594827994704247,\n",
              " 0.02119634672999382,\n",
              " -0.00915207713842392,\n",
              " 0.016909880563616753,\n",
              " -0.004864684771746397,\n",
              " -0.04887760058045387,\n",
              " 0.009757605381309986,\n",
              " 0.014907198026776314,\n",
              " -0.002883923938497901,\n",
              " -0.04564656689763069,\n",
              " 0.03230200335383415,\n",
              " 0.010500935837626457,\n",
              " 0.04341685026884079,\n",
              " -0.030890697613358498,\n",
              " -0.04172898456454277,\n",
              " 0.0466056652367115,\n",
              " -0.04470952972769737,\n",
              " -0.015634708106517792,\n",
              " -0.001096002641133964,\n",
              " -0.03364963084459305,\n",
              " 0.04645265266299248,\n",
              " -0.011740130372345448,\n",
              " -0.04238651692867279,\n",
              " -0.012610966339707375,\n",
              " -0.02940370701253414,\n",
              " 0.00985382217913866,\n",
              " 0.02620776928961277,\n",
              " -0.023693712428212166,\n",
              " 0.03308573737740517,\n",
              " 0.06376034766435623,\n",
              " -0.01650662161409855,\n",
              " -0.019661933183670044,\n",
              " 0.04913767799735069,\n",
              " 0.07543166726827621,\n",
              " -0.053704891353845596,\n",
              " 0.005619672127068043,\n",
              " -0.0033336032647639513,\n",
              " -0.0055834283120930195,\n",
              " 0.051564354449510574,\n",
              " 0.061844103038311005,\n",
              " -0.002648770809173584,\n",
              " 0.020558258518576622,\n",
              " -0.017518118023872375,\n",
              " 0.001622669748030603,\n",
              " -0.009855985641479492,\n",
              " -0.02182750590145588,\n",
              " 0.05718701705336571,\n",
              " -0.022137993946671486,\n",
              " 0.022702757269144058,\n",
              " -0.06804298609495163,\n",
              " 0.05262978374958038,\n",
              " 0.1002294197678566,\n",
              " 0.03900762274861336,\n",
              " 0.04343031346797943,\n",
              " -0.0025343713350594044,\n",
              " 0.049494460225105286,\n",
              " -0.005686819087713957,\n",
              " 0.022974763065576553,\n",
              " -0.027801640331745148,\n",
              " -0.04149286448955536,\n",
              " 0.0180069450289011,\n",
              " -0.007890569046139717,\n",
              " 0.011030204594135284,\n",
              " -0.048463426530361176,\n",
              " -0.021917281672358513,\n",
              " 0.0507342703640461,\n",
              " 0.020635871216654778,\n",
              " -0.05857257917523384,\n",
              " -0.032584916800260544,\n",
              " -0.00830670166760683,\n",
              " 0.06663987040519714,\n",
              " 0.002890732605010271,\n",
              " -0.011097842827439308,\n",
              " -0.0222642682492733,\n",
              " 0.03643762320280075,\n",
              " -0.015458803623914719,\n",
              " -0.03205230087041855,\n",
              " -0.004226985853165388,\n",
              " -0.0021259502973407507,\n",
              " -0.030173320323228836,\n",
              " -0.03583113104104996,\n",
              " -0.03873337432742119,\n",
              " 0.10200298577547073,\n",
              " 0.011362385004758835,\n",
              " 0.0030778220389038324,\n",
              " 0.006193910259753466,\n",
              " 0.011860169470310211,\n",
              " 0.05302119627594948]"
            ]
          },
          "execution_count": 106,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text = \"This is a sentence to embed.\"\n",
        "query_result = embeddings.embed_query(text)\n",
        "query_result"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
