{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EWxeTLVPF-e5",
        "outputId": "0d7165ef-453b-4fc1-e6f2-c5a69df76e31"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "['©', 'Manning', 'Publications', 'Co.', 'To', 'comment', 'go', 'to', 'liveBook', 'Licensed', 'to', 'Ursula', 'Deriu', 'Deriu', \"<ursula.deriu@gmail.com>'\"]\n",
            "ist drin\n"
          ]
        }
      ],
      "source": [
        "additional_string = \"\"\"\n",
        "© Manning Publications Co. To comment go to liveBook Licensed to Ursula Deriu Deriu <ursula.deriu@gmail.com>'\n",
        "\"\"\"\n",
        "more_words = additional_string.split()\n",
        "print(more_words)\n",
        "token = 'Deriu'\n",
        "if token not in more_words:\n",
        "  print('ist nicht drin')\n",
        "else:\n",
        "  print('ist drin')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_gIePRtyINYK"
      },
      "source": [
        "## OpenAI API key\n",
        "\n",
        "For this demo, we are going to use chatgpt-3.5 Turbo. For that, it is necessary to introduce the API key. Check [How to get an OPEN API key for ChatGPT](https://www.maisieai.com/help/how-to-get-an-openai-api-key-for-chatgpt) for instructions on how to get one."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "zF-pM0cNIMqy"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "from openai import OpenAI\n",
        "import os\n",
        "load_dotenv()\n",
        "\n",
        "\n",
        "llm = OpenAI()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F-QfH7Zm9Ci2",
        "outputId": "2c671652-950c-4392-fd8e-a22d8df7fcd4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AI-Powered_Search_v20.pdf       AI-Powered_Search_v20_Chap2.pdf\n",
            "AI-Powered_Search_v20_Ch2ff.pdf sudel.pdf\n",
            "AI-Powered_Search_v20_Chap1.pdf\n"
          ]
        }
      ],
      "source": [
        "!ls ./data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {},
      "outputs": [],
      "source": [
        "file = \"./data/AI-Powered_Search_v20_Chap2.pdf\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " The article covers the use of natural language in search engines, including techniques like distributional semantics and word embeddings. It also discusses challenges in natural language understanding and the importance of user intent and behavior. The use of Large Language Models and methods for representing domain-specific knowledge are also explored. The limitations of traditional search engines and the potential for word embeddings to improve search results are discussed.\n"
          ]
        }
      ],
      "source": [
        "from langchain.chains.summarize import load_summarize_chain\n",
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.llms import OpenAI\n",
        "\n",
        "def summarize_pdf(file, chain_type=\"map_reduce\"):\n",
        "\n",
        "  loader = PyPDFLoader(file)\n",
        "  documents = loader.load()\n",
        "  text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "  texts = text_splitter.split_documents(documents)\n",
        "\n",
        "  # Initialize LLM (Replace 'YOUR_API_KEY' with your actual OpenAI API key)\n",
        "  llm = OpenAI(temperature=0, max_tokens=1000)\n",
        "  chain = load_summarize_chain(llm, chain_type=chain_type)  # Specify map_reduce\n",
        "\n",
        "  summary = chain.run(texts)\n",
        "  return summary\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    \n",
        "    summary = summarize_pdf(file)\n",
        "    print(summary)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.8"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
